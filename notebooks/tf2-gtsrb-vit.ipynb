{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic sign classification with ViT\n",
    "\n",
    "In this notebook, we'll finetune a [Vision Transformer](https://arxiv.org/abs/2010.11929) (ViT) to classify images of traffic signs from [The German Traffic Sign Recognition Benchmark](http://benchmark.ini.rub.de/?section=gtsrb&subsection=news) using TensorFlow 2 / Keras and HuggingFace's [Transformers](https://github.com/huggingface/transformers). \n",
    "\n",
    "**Note that using a GPU with this notebook is highly recommended.**\n",
    "\n",
    "First, the needed imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from transformers import ViTFeatureExtractor, TFViTForImageClassification\n",
    "from transformers.utils import check_min_version\n",
    "from transformers import __version__ as transformers_version\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from PIL import Image\n",
    "\n",
    "import os, sys, datetime\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "check_min_version(\"4.13.0.dev0\")\n",
    "\n",
    "print('Using TensorFlow version:', tf.__version__,\n",
    "      'Keras version:', tf.keras.__version__,\n",
    "      'Transformers version:', transformers_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The training dataset consists of 5535 images of traffic signs of varying size. There are 43 different types of traffic signs:\n",
    "\n",
    "![title](imgs/gtsrb-montage.png)\n",
    "\n",
    "The validation and test sets consist of 999 and 12630 images, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"/media/data/gtsrb/train-5535/\"\n",
    "nimages = {'train':5535, 'validation':999, 'test':12630}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image paths and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths(dataset):\n",
    "    data_root = pathlib.Path(datapath+dataset)\n",
    "    image_paths = list(data_root.glob('*/*'))\n",
    "    image_paths = [str(path) for path in image_paths]\n",
    "    image_count = len(image_paths)\n",
    "    assert image_count == nimages[dataset], \"Found {} images, expected {}\".format(image_count, nimages[dataset])\n",
    "    return image_paths\n",
    "\n",
    "image_paths = dict()\n",
    "image_paths['train'] = get_paths('train')\n",
    "image_paths['validation'] = get_paths('validation')\n",
    "image_paths['test'] = get_paths('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = sorted(item.name for item in pathlib.Path(datapath+'train').glob('*/') if item.is_dir())\n",
    "label_to_index = dict((name, index) for index,name in enumerate(label_names))\n",
    "\n",
    "def get_labels(dataset):\n",
    "    return [label_to_index[pathlib.Path(path).parent.name]\n",
    "            for path in image_paths[dataset]]\n",
    "    \n",
    "image_labels = dict()\n",
    "image_labels['train'] = get_labels('train')\n",
    "image_labels['validation'] = get_labels('validation')\n",
    "image_labels['test'] = get_labels('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading\n",
    "\n",
    "First we specify the pre-trained ViT model we are going to use. The model [`\"google/vit-base-patch16-224\"`](https://huggingface.co/google/vit-base-patch16-224) is pre-trained on ImageNet-21k (14 million images, 21,843 classes) at resolution 224x224, and fine-tuned on ImageNet 2012 (1 million images, 1,000 classes) at resolution 224x224. \n",
    "\n",
    "We'll use a pre-trained ViT feature extractor that matches the ViT model to preprocess the input images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VITMODEL = 'google/vit-base-patch16-224'\n",
    "\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(VITMODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define functions to load and preprocess the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _load_and_process_image(path, label):\n",
    "    img = Image.open(path.numpy()).convert(\"RGB\")\n",
    "    proc_img = feature_extractor(images=img, return_tensors=\"np\")['pixel_values']\n",
    "    return np.squeeze(proc_img), label\n",
    "\n",
    "def load_and_process_image(path, label):\n",
    "    image, label = tf.py_function(_load_and_process_image, \n",
    "                                  (path, label), (tf.float32, tf.int32))\n",
    "    image.set_shape([None, None, None])\n",
    "    label.set_shape([])\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TF Datasets\n",
    "\n",
    "Let's now define our TF `Dataset`s for training and validation data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices((image_paths['train'],\n",
    "                                                    image_labels['train']))\n",
    "dataset_train = dataset_train.map(load_and_process_image,\n",
    "                                  num_parallel_calls=tf.data.AUTOTUNE)\n",
    "dataset_train = dataset_train.shuffle(len(dataset_train)).batch(BATCH_SIZE,\n",
    "                                                                drop_remainder=True)\n",
    "\n",
    "dataset_validation = tf.data.Dataset.from_tensor_slices((image_paths['validation'],\n",
    "                                                         image_labels['validation']))\n",
    "dataset_validation = dataset_validation.map(load_and_process_image,\n",
    "                                  num_parallel_calls=tf.data.AUTOTUNE)\n",
    "dataset_validation = dataset_validation.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model\n",
    "\n",
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFViTForImageClassification.from_pretrained(VITMODEL, num_labels=43,\n",
    "                                                    ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-5\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LR)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join(\n",
    "    os.getcwd(), \"logs\",\n",
    "    \"gtsrb-vit-\"+datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "print('TensorBoard log directory:', logdir)\n",
    "os.makedirs(logdir)\n",
    "callbacks = [TensorBoard(log_dir=logdir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "EPOCHS = 4\n",
    "\n",
    "history = model.fit(dataset_train,\n",
    "                    validation_data=dataset_validation,\n",
    "                    epochs=EPOCHS, verbose=2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,3))\n",
    "\n",
    "ax1.plot(history.epoch,history.history['loss'], label='training')\n",
    "ax1.plot(history.epoch,history.history['val_loss'], label='validation')\n",
    "ax1.set_title('loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.legend(loc='best')\n",
    "\n",
    "ax2.plot(history.epoch,history.history['accuracy'], label='training')\n",
    "ax2.plot(history.epoch,history.history['val_accuracy'], label='validation')\n",
    "ax2.set_title('accuracy')\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Inference\n",
    "\n",
    "We now evaluate the model using the test set. First we'll define the TF `Dataset` for the test images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = tf.data.Dataset.from_tensor_slices((image_paths['test'],\n",
    "                                                   image_labels['test']))\n",
    "dataset_test = dataset_test.map(load_and_process_image,\n",
    "                                num_parallel_calls=tf.data.AUTOTUNE)\n",
    "dataset_test = dataset_test.batch(BATCH_SIZE, drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "scores = model.evaluate(dataset_test, verbose=2)\n",
    "print(\"Test set %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.7",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
