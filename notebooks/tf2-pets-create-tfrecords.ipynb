{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Creating TFRecord files for Pet images\n",
    "\n",
    "In this example notebook, we will create TFRecord files from an image dataset.\n",
    "\n",
    "The [TFRecord format](https://www.tensorflow.org/tutorials/load_data/tfrecord) is a simple format for storing a sequence of binary records. By converting our data into TFRecord records we can store the data in an efficient and convenient way. Instead of lots of small files the data is stored in a small number of large files where all data belonging to a specific sample is collected into a single record. Furthermore, the TFRecord format can be read sequentially with fast and parallel IO operations, which is especially useful when using multiple GPUs.\n",
    "\n",
    "The image dataset used in this notebook is [The Oxford-IIIT Pet Dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/). The dataset contains images of breeds of dogs and cats. There are 37 breed categories with roughly 200 images for each category.\n",
    "\n",
    "This notebook is partly based on the tutorials [\"TFRecord and tf.train.Example\"](https://www.tensorflow.org/tutorials/load_data/tfrecord) and [\"Creating TFRecords\"](https://keras.io/examples/keras_recipes/creating_tfrecords/).\n",
    "\n",
    "We begin with the needed imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Tensorflow version: 2.7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import os\n",
    "import tarfile\n",
    "import re\n",
    "\n",
    "print('Using Tensorflow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "In this example, the original data is stored as JPG files in a tar file `images.tar.gz` downloaded into the directory `\"/media/data/pets\"`. In total there are 7390 JPG images, belonging to 37 different cat and dog breed categories (e.g. *\"boxer\", \"chihuahua\"*, and *\"Egyptian_Mau\"*). The category of an image is specified in the filename of the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of JPG images: 7390\n",
      "First 10 files: ['images', 'images/boxer_16.jpg', 'images/chihuahua_165.jpg', 'images/pug_183.jpg', 'images/english_setter_1.jpg', 'images/chihuahua_170.jpg', 'images/english_cocker_spaniel_17.jpg', 'images/samoyed_39.jpg', 'images/Egyptian_Mau_62.jpg', 'images/samoyed_36.jpg']\n"
     ]
    }
   ],
   "source": [
    "DATADIR = \"/media/data/pets\"\n",
    "\n",
    "tarfilename = DATADIR + \"/images.tar.gz\"\n",
    "assert os.path.exists(tarfilename), \"File not found: \"+tarfilename\n",
    "\n",
    "with tarfile.open(tarfilename) as tar:\n",
    "    filenames = tar.getnames()\n",
    "    print('Total number of JPG images:', sum(['jpg' in f for f in filenames]))\n",
    "    print('First 10 files:', filenames[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TFRecord files\n",
    "\n",
    "First we define a set of helper functions to convert standard datatypes (bytes, strings, integers) to a `tf.train.Example`-compatible `tf.train.Feature`s. \n",
    "\n",
    "Then we define the function `create_example()` to create `tf.train.Example` messages containing all the features of each image. The used features include:\n",
    "* `\"image\"`: image data as bytes \n",
    "* `\"filename\"`: original file name of the image in the input tar file\n",
    "* `\"classname\"`: pet category of the image, extracted from the image file name\n",
    "* `\"classidx\"`: integer index of the pet category of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def str_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.encode()]))\n",
    "\n",
    "def int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def create_example(image, filename, classname, classidx):\n",
    "    feature = {\n",
    "        \"image\": image_feature(image),\n",
    "        \"filename\": str_feature(filename),\n",
    "        \"classname\": str_feature(classname),\n",
    "        \"classidx\": int64_feature(classidx),\n",
    "    }\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We process every JPG image in the tar file and write a corresponding TFRecord entry. We split the TFRecord entries into `N_SHARDS = 10` distinct TFRecord files named `\"images_XXX.tfrec\"` (where `XXX` is the zero-padded shard number). \n",
    "\n",
    "We can store either JPG-encoded image data in the TFRecord files, or decode and preprocess the images first.\n",
    "In the latter option (`STORE_DECODED_IMAGES = True`), the TFRecord files will contain serialized `tf.Tensor`s with the RGB pixel values of the images. This will make the TFRecord files larger in size, but, on the other hand, eliminate the need for image decoding when reading the image data from the TFRecord files.\n",
    "\n",
    "The category of the image is extracted from the image file name and the categories are mapped into integer indices starting from zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SHARDS = 10\n",
    "STORE_DECODED_IMAGES = False\n",
    "\n",
    "tar = tarfile.open(tarfilename)\n",
    "classindices = {}\n",
    "shards = np.array_split(tar.getmembers(), N_SHARDS)\n",
    "\n",
    "for i, shard in enumerate(shards):\n",
    "    tfrecfilename = \"images_{:03d}.tfrec\".format(i)\n",
    "    with tf.io.TFRecordWriter(os.path.join(DATADIR, tfrecfilename)) as writer:\n",
    "        n_images = 0\n",
    "        for member in shard:\n",
    "            if member.name.endswith(\".jpg\"):\n",
    "                imagedata = tar.extractfile(member).read()\n",
    "                if STORE_DECODED_IMAGES:\n",
    "                    imagedata = tf.image.decode_jpeg(imagedata)\n",
    "                    imagedata = tf.image.resize(imagedata, [256, 256])\n",
    "                    imagedata = tf.cast(imagedata, tf.uint8)\n",
    "                    imagedata = tf.io.serialize_tensor(imagedata).numpy()\n",
    "                n_images += 1\n",
    "                classname = re.findall(\"^.*/(.*)_\\d+.jpg$\", member.name)[0]\n",
    "                if not (classname in classindices):\n",
    "                    classindices[classname] = len(classindices)\n",
    "\n",
    "                example = create_example(imagedata, member.name,\n",
    "                                         classname, classindices[classname])\n",
    "                writer.write(example.SerializeToString())\n",
    "        print(\"Wrote {} records in {} (shard {})\".format(n_images, tfrecfilename, i))\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the produced TFRecord files on disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$DATADIR\"\n",
    "\n",
    "ls -lh $1/images_???.tfrec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data from TFRecord files\n",
    "\n",
    "To test the validity of the produced TFRecord files, we'll now read and plot some images from them.\n",
    "\n",
    "We define a function `load_image()` to load images from the TFRecord entries. The function first parses a `tf.train.Example` message into a dictionary mapping feature keys to `tf.Tensor`s. Here we only use the `\"image\"` and `\"classidx\"` entries in the dictionary. \n",
    "\n",
    "If the TFRecord files contain JPG-encoded image data, the images are decoded and preprocessed by resizing to a fixed size. Otherwise, the image `tf.Tensor` is only parsed back from the serialization, as the preprocessing has already been done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    if STORE_DECODED_IMAGES:\n",
    "        return tf.io.parse_tensor(image, tf.uint8)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [256, 256])\n",
    "    return tf.cast(image, tf.uint8)\n",
    "\n",
    "feature_description = {\n",
    "    \"image\": tf.io.FixedLenFeature((), tf.string),\n",
    "    \"filename\": tf.io.FixedLenFeature((), tf.string),\n",
    "    \"classname\": tf.io.FixedLenFeature((), tf.string),\n",
    "    \"classidx\": tf.io.FixedLenFeature((), tf.int64)}\n",
    "\n",
    "def load_image(example_proto):\n",
    "    ex = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    return (preprocess_image(ex[\"image\"]), ex[\"classidx\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define out `tf.data` input pipeline. We use the `TFRecordDataset` class, which can read the data records from multiple TFRecord files. \n",
    "\n",
    "TFRecord files contain sequences of data records and can only be read sequentially. To randomize the order of the data samples, we both shuffle the shards and use a (small) shuffle buffer when reading the data records. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filenames = [DATADIR+\"/images_{:03d}.tfrec\".format(i)\n",
    "                   for i in range(N_SHARDS)]\n",
    "random.shuffle(train_filenames)\n",
    "\n",
    "train_dataset = tf.data.TFRecordDataset(train_filenames)\n",
    "train_dataset = train_dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(128).batch(32, drop_remainder=False)\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot some random images read from the resulting TFRecord files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(13,13))\n",
    "classnames = list(classindices.keys())\n",
    "for batch, labelidx in train_dataset.take(1):\n",
    "    for i in range(16):    \n",
    "        plt.subplot(4,4,i+1)\n",
    "        plt.imshow(batch[i])\n",
    "        lidx = labelidx[i].numpy()\n",
    "        plt.title(\"{} ({})\".format(classnames[lidx], lidx))\n",
    "        plt.grid(False)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.suptitle('Some images from the Oxford-IIIT Pet Dataset', fontsize=16, y=0.93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.7",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
