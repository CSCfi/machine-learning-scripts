{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs-vs-cats classification with CNNs\n",
    "\n",
    "In this notebook, we'll train a convolutional neural network (CNN, ConvNet) to classify images of dogs from images of cats using Keras (version $\\ge$ 2 is required). This notebook is largely based on the blog post [Building powerful image classification models using very little data](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html) by FranÃ§ois Chollet.\n",
    "\n",
    "**Note that using a GPU with this notebook is highly recommended.**\n",
    "\n",
    "First, the needed imports. Keras tells us which backend (Theano, Tensorflow, CNTK) it will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, MaxPooling2D, InputLayer\n",
    "from keras.layers.convolutional import Conv2D \n",
    "from keras.preprocessing.image import (ImageDataGenerator, array_to_img, \n",
    "                                      img_to_array, load_img)\n",
    "from keras import applications, optimizers\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "from distutils.version import LooseVersion as LV\n",
    "from keras import __version__\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print('Using Keras version:', __version__, 'backend:', K.backend())\n",
    "assert(LV(__version__) >= LV(\"2.0.0\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are using TensorFlow as the backend, we can use TensorBoard to visualize our progress during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.backend() == \"tensorflow\":\n",
    "    import tensorflow as tf\n",
    "    from keras.callbacks import TensorBoard\n",
    "    import os, datetime\n",
    "    logdir = os.path.join(os.getcwd(), \"logs\",\n",
    "                     \"dvc-\"+datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "    print('TensorBoard log directory:', logdir)\n",
    "    os.makedirs(logdir)\n",
    "    callbacks = [TensorBoard(log_dir=logdir)]\n",
    "else:\n",
    "    callbacks =  None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The training dataset consists of 2000 images of dogs and cats, split in half.  In addition, the validation set consists of 1000 images, and the test set of 22000 images.  Here are some random training images:\n",
    "\n",
    "![title](imgs/dvc.png)\n",
    "\n",
    "### Downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"/media/data/dogs-vs-cats/train-2000\"\n",
    "(nimages_train, nimages_validation, nimages_test) = (2000, 1000, 22000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation\n",
    "\n",
    "First, we'll resize all training and validation images to a fixed size. \n",
    "\n",
    "Then, to make the most of our limited number of training examples, we'll apply random transformations to them each time we are looping over them. This way, we \"augment\" our training dataset to contain more data. There are various transformations readily available in Keras, see [ImageDataGenerator](https://keras.io/preprocessing/image/) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_size = (160, 160)\n",
    "#input_image_size = (150, 150)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        #rotation_range=40,\n",
    "        #width_shift_range=0.2,\n",
    "        #height_shift_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "noopgen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see a couple of training images with and without the augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_generator = noopgen.flow_from_directory(\n",
    "        datapath+'/train',  \n",
    "        target_size=input_image_size,  \n",
    "        batch_size=9)\n",
    "\n",
    "augm_generator = datagen.flow_from_directory(\n",
    "        datapath+'/train',  \n",
    "        target_size=input_image_size,  \n",
    "        batch_size=9)\n",
    "\n",
    "for batch, _ in orig_generator:\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(9):\n",
    "        plt.subplot(3,3,i+1)\n",
    "        plt.imshow(batch[i,:,:,:])\n",
    "        plt.suptitle('only resized training images', fontsize=16, y=0.93)\n",
    "    break\n",
    "\n",
    "for batch, _ in augm_generator:\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(9):\n",
    "        plt.subplot(3,3,i+1)\n",
    "        plt.imshow(batch[i,:,:,:])\n",
    "        plt.suptitle('augmented training images', fontsize=16, y=0.93)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's insert the augmented images also to a TensorBoard event file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.backend() == \"tensorflow\":\n",
    "    imgs = tf.convert_to_tensor(batch)\n",
    "    summary_op = tf.summary.image(\"augmented\", imgs, max_outputs=9)\n",
    "    with tf.Session() as sess:\n",
    "        summary = sess.run(summary_op)\n",
    "        writer = tf.summary.FileWriter(logdir)\n",
    "        writer.add_summary(summary)\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loaders\n",
    "\n",
    "Let's now define our real data loaders for training, validation, and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 25\n",
    "\n",
    "print('Train: ', end=\"\")\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        datapath+'/train',  \n",
    "        target_size=input_image_size,\n",
    "        batch_size=batch_size, \n",
    "        class_mode='binary')\n",
    "\n",
    "print('Validation: ', end=\"\")\n",
    "validation_generator = noopgen.flow_from_directory(\n",
    "        datapath+'/validation',  \n",
    "        target_size=input_image_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "print('Test: ', end=\"\")\n",
    "test_generator = noopgen.flow_from_directory(\n",
    "        datapath+'/test',  \n",
    "        target_size=input_image_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Train a small CNN from scratch\n",
    "\n",
    "Similarly as with MNIST digits, we can start from scratch and train a CNN for the classification task. However, due to the small number of training images, a large network will easily overfit, regardless of the data augmentation.\n",
    "\n",
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_image_size+(3,), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 20 \n",
    "        \n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=nimages_train // batch_size,\n",
    "                              epochs=epochs,\n",
    "                              validation_data=validation_generator,\n",
    "                              validation_steps=nimages_validation // batch_size,\n",
    "                              verbose=2, callbacks=callbacks,\n",
    "                              workers=4, use_multiprocessing=True)\n",
    "\n",
    "model.save(\"dvc-small-cnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(history.epoch,history.history['loss'], label='training')\n",
    "plt.plot(history.epoch,history.history['val_loss'], label='validation')\n",
    "plt.title('loss')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(history.epoch,history.history['acc'], label='training')\n",
    "plt.plot(history.epoch,history.history['val_acc'], label='validation')\n",
    "plt.title('accuracy')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "scores = model.evaluate_generator(test_generator,\n",
    "                                  steps=nimages_test // batch_size)\n",
    "print(\"Test set %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Reuse a pre-trained CNN\n",
    "\n",
    "Another option is to reuse a pretrained network.  Here we'll use one of the [pre-trained networks available from Keras](https://keras.io/applications/).  We remove the top layers and freeze the pre-trained weights. \n",
    "\n",
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(InputLayer(input_shape=input_image_size+(3,)))  # possibly needed due to a bug in Keras                                           \n",
    "\n",
    "pt_model = applications.VGG16(weights='imagenet', include_top=False,                                                                      \n",
    "                              input_shape=input_image_size+(3,))                                                                          \n",
    "# pt_model = applications.MobileNet(weights='imagenet', include_top=False,\n",
    "#                                  input_shape=input_image_size+(3,))\n",
    "\n",
    "pt_name = pt_model.name\n",
    "print('Using {} pre-trained model'.format(pt_name))\n",
    "\n",
    "for layer in pt_model.layers:\n",
    "    model.add(layer)\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then stack our own, randomly initialized layers on top of the pre-trained network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning 1: New layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=nimages_train // batch_size,\n",
    "                              epochs=epochs,\n",
    "                              validation_data=validation_generator,\n",
    "                              validation_steps=nimages_validation // batch_size,\n",
    "                              verbose=2, callbacks=callbacks,\n",
    "                              workers=4, use_multiprocessing=True)\n",
    "\n",
    "model.save(\"dvc-\" + pt_name + \"-reuse.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(history.epoch,history.history['loss'], label='training')\n",
    "plt.plot(history.epoch,history.history['val_loss'], label='validation')\n",
    "plt.title('loss')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(history.epoch,history.history['acc'], label='training')\n",
    "plt.plot(history.epoch,history.history['val_acc'], label='validation')\n",
    "plt.title('accuracy')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning 2: Fine-tuning\n",
    "\n",
    "Once the top layers have learned some reasonable weights, we can continue training by unfreezing the last blocks of the pre-trained network so that it may adapt to our data. The learning rate should be smaller than usual. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[15:]:   # VGG16\n",
    "#for layer in model.layers[75:]:    # MobileNet                                                                                                \n",
    "    layer.trainable = True\n",
    "    print(layer.name, \"now trainable\")\n",
    "    \n",
    "model.compile(loss='binary_crossentropy',\n",
    "    optimizer=optimizers.RMSprop(lr=1e-5),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "#print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that before continuing the training, we create a separate TensorBoard log directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "if K.backend() == \"tensorflow\":\n",
    "    logdir_ft = logdir + \"-ft\"\n",
    "    os.makedirs(logdir_ft)\n",
    "    callbacks_ft = [TensorBoard(log_dir=logdir_ft)]\n",
    "else:\n",
    "    callbacks_ft = None\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=nimages_train // batch_size,\n",
    "                              epochs=epochs,\n",
    "                              validation_data=validation_generator,\n",
    "                              validation_steps=nimages_validation // batch_size,\n",
    "                              verbose=2, callbacks=callbacks_ft,\n",
    "                              workers=4, use_multiprocessing=True)\n",
    "\n",
    "model.save(\"dvc-\" + pt_name + \"-finetune.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(history.epoch,history.history['loss'], label='training')\n",
    "plt.plot(history.epoch,history.history['val_loss'], label='validation')\n",
    "plt.title('loss')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(history.epoch,history.history['acc'], label='training')\n",
    "plt.plot(history.epoch,history.history['val_acc'], label='validation')\n",
    "plt.title('accuracy')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "scores = model.evaluate_generator(test_generator,\n",
    "                                  steps=nimages_test // batch_size,\n",
    "                                  workers=4, use_multiprocessing=True)\n",
    "print(\"Test set %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
