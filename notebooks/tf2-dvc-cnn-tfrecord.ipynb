{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs-vs-cats classification with CNNs\n",
    "\n",
    "In this notebook, we'll train a convolutional neural network (CNN, ConvNet) to classify images of dogs from images of cats using TensorFlow 2.0 / Keras. This notebook is largely based on the blog post [Building powerful image classification models using very little data](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html) by Fran√ßois Chollet.\n",
    "\n",
    "**Note that using a GPU with this notebook is highly recommended.**\n",
    "\n",
    "First, the needed imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os, datetime\n",
    "import random\n",
    "import pathlib\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Dense, Activation, Dropout, Conv2D,\n",
    "                                    Flatten, MaxPooling2D, InputLayer)\n",
    "from tensorflow.keras.preprocessing.image import (ImageDataGenerator, \n",
    "                                                  array_to_img, \n",
    "                                                  img_to_array, load_img)\n",
    "from tensorflow.keras import applications, optimizers\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "print('Using Tensorflow version:', tf.__version__,\n",
    "      'Keras version:', tf.keras.__version__,\n",
    "      'backend:', tf.keras.backend.backend())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The training dataset consists of 2000 images of dogs and cats, split in half.  In addition, the validation set consists of 1000 images, and the test set of 22000 images.  Here are some random training images:\n",
    "\n",
    "![title](imgs/dvc.png)\n",
    "\n",
    "### Downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"/media/data/dogs-vs-cats/train-2000/tfrecord/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "INPUT_IMAGE_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation\n",
    "\n",
    "We need to resize all training and validation images to a fixed size. Here we'll use 160x160 pixels. \n",
    "\n",
    "Then, to make the most of our limited number of training examples, we'll apply random transformations (crop and horizontal flip) to them each time we are looping over them. This way, we \"augment\" our training dataset to contain more data. There are various transformations readily available in TensorFlow, see [tf.image](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/image) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_IMAGE_SIZE = [160, 160, 3]\n",
    "\n",
    "def preprocess_image(image, augment):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    if augment:\n",
    "        image = tf.image.resize(image, [256, 256])\n",
    "        image = tf.image.random_crop(image, INPUT_IMAGE_SIZE)\n",
    "        if random.random() < 0.5:\n",
    "            image = tf.image.flip_left_right(image)\n",
    "    else:\n",
    "        image = tf.image.resize(image, INPUT_IMAGE_SIZE[:2])\n",
    "    image /= 255.0  # normalize to [0,1] range\n",
    "    return image\n",
    "\n",
    "feature_description = {\n",
    "    \"image/encoded\": tf.io.FixedLenFeature((), tf.string, default_value=\"\"),\n",
    "    \"image/height\": tf.io.FixedLenFeature((), tf.int64, default_value=0),\n",
    "    \"image/width\": tf.io.FixedLenFeature((), tf.int64, default_value=0),\n",
    "    \"image/colorspace\": tf.io.FixedLenFeature((), tf.string, default_value=\"\"),\n",
    "    \"image/channels\": tf.io.FixedLenFeature((), tf.int64, default_value=0),\n",
    "    \"image/format\": tf.io.FixedLenFeature((), tf.string, default_value=\"\"),\n",
    "    \"image/filename\": tf.io.FixedLenFeature((), tf.string, default_value=\"\"),\n",
    "    \"image/class/label\": tf.io.FixedLenFeature((), tf.int64, default_value=0),\n",
    "    \"image/class/text\": tf.io.FixedLenFeature((), tf.string, default_value=\"\")}\n",
    "\n",
    "def load_and_augment_image(example_proto):\n",
    "    ex = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    return (preprocess_image(ex[\"image/encoded\"], True),\n",
    "            ex[\"image/class/label\"]-1)\n",
    "\n",
    "def load_and_not_augment_image(example_proto):\n",
    "    ex = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    return (preprocess_image(ex[\"image/encoded\"], False),\n",
    "            ex[\"image/class/label\"]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF Datasets\n",
    "\n",
    "Let's now define our [TF `Dataset`s](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset#class_dataset) for training, validation, and test data. We use the [TFRecordDataset](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/TFRecordDataset) class, which reads the data records from multiple TFRecord files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filenames = [datapath+\"train-{0:05d}-of-00004\".format(i)\n",
    "                   for i in range(4)]\n",
    "train_dataset = tf.data.TFRecordDataset(train_filenames)\n",
    "\n",
    "validation_filenames = [datapath+\"validation-{0:05d}-of-00002\".format(i)\n",
    "                        for i in range(2)]\n",
    "validation_dataset = tf.data.TFRecordDataset(validation_filenames)\n",
    "\n",
    "test_filenames = [datapath+\"test-{0:05d}-of-00022\".format(i)\n",
    "                   for i in range(22)]\n",
    "test_dataset = tf.data.TFRecordDataset(test_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then `map()` the records to the actual image data and decode the images.\n",
    "Note that we shuffle and augment only the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataset = train_dataset.map(load_and_augment_image, num_parallel_calls=10)\n",
    "train_dataset = train_dataset.shuffle(2000).batch(BATCH_SIZE, drop_remainder=True)\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "validation_dataset = validation_dataset.map(load_and_not_augment_image, num_parallel_calls=10)\n",
    "validation_dataset = validation_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "test_dataset = test_dataset.map(load_and_not_augment_image, num_parallel_calls=10)\n",
    "test_dataset = test_dataset.shuffle(2000).batch(BATCH_SIZE, drop_remainder=False)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see a couple of augmented training images and not augmented validation images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = {0: 'cats', 1: 'dogs'}\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for batch, labels in train_dataset.take(1):\n",
    "    for i in range(9):    \n",
    "        plt.subplot(3,3,i+1)\n",
    "        plt.imshow(batch[i,:,:,:])\n",
    "        plt.title(label_names[labels[i].numpy()])\n",
    "        plt.grid(False)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.suptitle('augmented training images', fontsize=16, y=0.93)\n",
    "    \n",
    "plt.figure(figsize=(10,10))\n",
    "for batch, labels in validation_dataset.take(1):\n",
    "    for i in range(9):    \n",
    "        plt.subplot(3,3,i+1)\n",
    "        plt.imshow(batch[i,:,:,:])\n",
    "        plt.title(label_names[labels[i].numpy()])\n",
    "        plt.grid(False)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.suptitle('not augmented validation images', fontsize=16, y=0.93)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Train a small CNN from scratch\n",
    "\n",
    "Similarly as with MNIST digits, we can start from scratch and train a CNN for the classification task. However, due to the small number of training images, a large network will easily overfit, regardless of the data augmentation.\n",
    "\n",
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=INPUT_IMAGE_SIZE, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, 'tf2-dvc-small-cnn.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use TensorBoard to visualize our progress during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join(os.getcwd(), \"logs\",\n",
    "                      \"dvc-small-cnn-\"+datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "print('TensorBoard log directory:', logdir)\n",
    "os.makedirs(logdir)\n",
    "callbacks = [TensorBoard(log_dir=logdir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "history = model.fit(train_dataset, epochs=epochs, \n",
    "                    validation_data=validation_dataset,\n",
    "                    callbacks=callbacks, verbose=2)\n",
    "\n",
    "model.save(\"dvc-small-cnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(history.epoch,history.history['loss'], label='training')\n",
    "plt.plot(history.epoch,history.history['val_loss'], label='validation')\n",
    "plt.title('loss')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(history.epoch,history.history['accuracy'], label='training')\n",
    "plt.plot(history.epoch,history.history['val_accuracy'], label='validation')\n",
    "plt.title('accuracy')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "scores = model.evaluate(test_dataset, verbose=2)\n",
    "print(\"Test set %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Reuse a pre-trained CNN\n",
    "\n",
    "Another option is to reuse a pretrained network.  Here we'll use one of the [pre-trained networks available from Keras](https://keras.io/applications/).  We remove the top layers and freeze the pre-trained weights. \n",
    "\n",
    "We first choose either VGG16 or MobileNet as our pretrained network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = 'VGG16'\n",
    "#pretrained = 'MobileNet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "if pretrained == 'VGG16':\n",
    "    pt_model = applications.VGG16(weights='imagenet', include_top=False,      \n",
    "                                  input_shape=INPUT_IMAGE_SIZE)\n",
    "    pretrained_first_trainable_layer = 15 \n",
    "elif pretrained == 'MobileNet':\n",
    "    pt_model = applications.MobileNet(weights='imagenet', include_top=False,\n",
    "                                      input_shape=INPUT_IMAGE_SIZE)\n",
    "    pretrained_first_trainable_layer = 75\n",
    "else:\n",
    "    assert 0, \"Unknown model: \"+pretrained\n",
    "    \n",
    "pt_name = pt_model.name\n",
    "print('Using {} pre-trained model'.format(pt_name))\n",
    "\n",
    "for layer in pt_model.layers:\n",
    "    model.add(layer)\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then stack our own, randomly initialized layers on top of the pre-trained network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, 'tf2-dvc-'+pt_name+'-reuse.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning 1: New layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join(os.getcwd(), \"logs\",\n",
    "                      \"dvc-\"+pt_name+\"-reuse-\"+datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "print('TensorBoard log directory:', logdir)\n",
    "os.makedirs(logdir)\n",
    "callbacks = [TensorBoard(log_dir=logdir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "history = model.fit(train_dataset, epochs=epochs, \n",
    "                    validation_data=validation_dataset,\n",
    "                    callbacks=callbacks, verbose=2)\n",
    "\n",
    "model.save(\"dvc-\" + pt_name + \"-reuse.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(history.epoch,history.history['loss'], label='training')\n",
    "plt.plot(history.epoch,history.history['val_loss'], label='validation')\n",
    "plt.title('loss')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(history.epoch,history.history['accuracy'], label='training')\n",
    "plt.plot(history.epoch,history.history['val_accuracy'], label='validation')\n",
    "plt.title('accuracy')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning 2: Fine-tuning\n",
    "\n",
    "Once the top layers have learned some reasonable weights, we can continue training by unfreezing the last blocks of the pre-trained network so that it may adapt to our data. The learning rate should be smaller than usual. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[pretrained_first_trainable_layer:]:\n",
    "    layer.trainable = True\n",
    "    print(layer.name, \"now trainable\")\n",
    "    \n",
    "model.compile(loss='binary_crossentropy',\n",
    "    optimizer=optimizers.RMSprop(lr=1e-5),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "#print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join(os.getcwd(), \"logs\",\n",
    "                      \"dvc-\"+pt_name+\"-finetune-\"+datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "print('TensorBoard log directory:', logdir)\n",
    "os.makedirs(logdir)\n",
    "callbacks = [TensorBoard(log_dir=logdir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "history_ft = model.fit(train_dataset, epochs=epochs, \n",
    "                       validation_data=validation_dataset,\n",
    "                       callbacks=callbacks, verbose=2)\n",
    "\n",
    "model.save(\"dvc-\" + pt_name + \"-finetune.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(history.epoch, history.history['loss'], color='0.75')\n",
    "plt.plot(history.epoch, history.history['val_loss'], color='0.75')\n",
    "plt.plot([e+len(history.epoch) for e in history_ft.epoch],\n",
    "         history_ft.history['loss'], label='training')\n",
    "plt.plot([e+len(history.epoch) for e in history_ft.epoch],\n",
    "         history_ft.history['val_loss'], label='validation')\n",
    "plt.title('loss')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(history.epoch,history.history['accuracy'], color='0.75')\n",
    "plt.plot(history.epoch,history.history['val_accuracy'], color='0.75')\n",
    "plt.plot([e+len(history.epoch) for e in history_ft.epoch],\n",
    "         history_ft.history['accuracy'], label='training')\n",
    "plt.plot([e+len(history.epoch) for e in history_ft.epoch],\n",
    "         history_ft.history['val_accuracy'], label='validation')\n",
    "plt.title('accuracy')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "scores = model.evaluate(test_dataset, verbose=2)\n",
    "print(\"Test set %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.0",
   "language": "python",
   "name": "tf2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
