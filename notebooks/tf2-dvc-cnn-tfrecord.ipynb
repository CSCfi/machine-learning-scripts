{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs-vs-cats classification with CNNs\n",
    "\n",
    "In this notebook, we'll train a convolutional neural network (CNN, ConvNet) to classify images of dogs from images of cats using TensorFlow 2 / Keras. This notebook is largely based on the blog post [Building powerful image classification models using very little data](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html) by Fran√ßois Chollet.\n",
    "\n",
    "This version reads the image data from TFRecord files.\n",
    "\n",
    "**Note that using a GPU with this notebook is highly recommended.**\n",
    "\n",
    "First, the needed imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os, datetime\n",
    "import pathlib\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import applications, optimizers\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "print('Using Tensorflow version:', tf.__version__,\n",
    "      'Keras version:', tf.keras.__version__,\n",
    "      'backend:', tf.keras.backend.backend())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The training dataset consists of 2000 images of dogs and cats, split in half.  In addition, the validation set consists of 1000 images, and the test set of 22000 images.  Here are some random training images:\n",
    "\n",
    "![title](imgs/dvc.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"/media/data/dogs-vs-cats/train-2000/tfrecord/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading\n",
    "\n",
    "We now define a function to load the images from TFRecord entries. Also we need to resize the images to a fixed size (`INPUT_IMAGE_SIZE`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_IMAGE_SIZE = [256, 256]\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    return tf.image.resize(image, INPUT_IMAGE_SIZE)\n",
    "\n",
    "feature_description = {\n",
    "    \"image/encoded\": tf.io.FixedLenFeature((), tf.string, default_value=\"\"),\n",
    "    \"image/height\": tf.io.FixedLenFeature((), tf.int64, default_value=0),\n",
    "    \"image/width\": tf.io.FixedLenFeature((), tf.int64, default_value=0),\n",
    "    \"image/colorspace\": tf.io.FixedLenFeature((), tf.string, default_value=\"\"),\n",
    "    \"image/channels\": tf.io.FixedLenFeature((), tf.int64, default_value=0),\n",
    "    \"image/format\": tf.io.FixedLenFeature((), tf.string, default_value=\"\"),\n",
    "    \"image/filename\": tf.io.FixedLenFeature((), tf.string, default_value=\"\"),\n",
    "    \"image/class/label\": tf.io.FixedLenFeature((), tf.int64, default_value=0),\n",
    "    \"image/class/text\": tf.io.FixedLenFeature((), tf.string, default_value=\"\")}\n",
    "\n",
    "def load_image(example_proto):\n",
    "    ex = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    return (preprocess_image(ex[\"image/encoded\"]), ex[\"image/class/label\"]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF Datasets\n",
    "\n",
    "Let's now define our [TF `Dataset`s](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) for training, validation, and test data. We use the [TFRecordDataset](https://www.tensorflow.org/api_docs/python/tf/data/TFRecordDataset) class, which reads the data records from multiple TFRecord files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filenames = [datapath+\"train-{0:05d}-of-00004\".format(i)\n",
    "                   for i in range(4)]\n",
    "train_dataset = tf.data.TFRecordDataset(train_filenames)\n",
    "\n",
    "validation_filenames = [datapath+\"validation-{0:05d}-of-00002\".format(i)\n",
    "                        for i in range(2)]\n",
    "validation_dataset = tf.data.TFRecordDataset(validation_filenames)\n",
    "\n",
    "test_filenames = [datapath+\"test-{0:05d}-of-00022\".format(i)\n",
    "                   for i in range(22)]\n",
    "test_dataset = tf.data.TFRecordDataset(test_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then `map()` the records to the actual image data and decode the images.\n",
    "Note that we shuffle and augment only the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataset = train_dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(2000).batch(BATCH_SIZE, drop_remainder=True)\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "validation_dataset = validation_dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "validation_dataset = validation_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "test_dataset = test_dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see a couple of augmented training images and not augmented validation images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = {0: 'cats', 1: 'dogs'}\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for batch, labels in train_dataset.take(1):\n",
    "    for i in range(9):    \n",
    "        plt.subplot(3,3,i+1)\n",
    "        plt.imshow(tf.cast(batch[i,:,:,:], tf.int32))\n",
    "        plt.title(label_names[labels[i].numpy()])\n",
    "        plt.grid(False)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.suptitle('some training images', fontsize=16, y=0.93)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Option 1: Train a small CNN from scratch\n",
    "\n",
    "Similarly as with MNIST digits, we can start from scratch and train a CNN for the classification task.\n",
    "\n",
    "However, due to the small number of training images, a large network will easily overfit.\n",
    "Therefore, to make the most of our limited number of training examples, we'll apply random augmentation transformations (crop and horizontal flip) to them each time we are looping over them. This way, we \"augment\" our training dataset to contain more data.\n",
    "\n",
    "The augmentation transformations are implemented as preprocessing layers in Keras.\n",
    "There are various such layers readily available, see [https://keras.io/guides/preprocessing_layers/](https://keras.io/guides/preprocessing_layers/) for more information.\n",
    "\n",
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=INPUT_IMAGE_SIZE+[3])\n",
    "x = layers.Rescaling(scale=1./255)(inputs)\n",
    "\n",
    "x = layers.RandomCrop(160, 160)(x)\n",
    "x = layers.RandomFlip(mode=\"horizontal\")(x)\n",
    "\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs,\n",
    "                    name=\"dvc-small-cnn\")\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, 'tf2-dvc-small-cnn.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use TensorBoard to visualize our progress during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join(os.getcwd(), \"logs\",\n",
    "                      \"dvc_tfr-small-cnn-\"+datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "print('TensorBoard log directory:', logdir)\n",
    "os.makedirs(logdir)\n",
    "callbacks = [TensorBoard(log_dir=logdir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "history = model.fit(train_dataset, epochs=epochs, \n",
    "                    validation_data=validation_dataset,\n",
    "                    callbacks=callbacks, verbose=2)\n",
    "\n",
    "model.save(\"dvc_tfr-small-cnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,3))\n",
    "\n",
    "ax1.plot(history.epoch,history.history['loss'], label='training')\n",
    "ax1.plot(history.epoch,history.history['val_loss'], label='validation')\n",
    "ax1.set_title('loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.legend(loc='best')\n",
    "\n",
    "ax2.plot(history.epoch,history.history['accuracy'], label='training')\n",
    "ax2.plot(history.epoch,history.history['val_accuracy'], label='validation')\n",
    "ax2.set_title('accuracy')\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "scores = model.evaluate(test_dataset, verbose=2)\n",
    "print(\"Test set %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Reuse a pre-trained CNN\n",
    "\n",
    "Another option is to reuse a pretrained network.  Here we'll use one of the [pre-trained networks available from Keras](https://keras.io/applications/).\n",
    "\n",
    "### Initialization\n",
    "\n",
    "We first choose either VGG16 or MobileNet as our pretrained network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = 'VGG16'\n",
    "#pretrained = 'MobileNet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll apply the same augmentation transformations as before, and load the pretrained network, remove the top layers, and freeze the pre-trained weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=INPUT_IMAGE_SIZE+[3])\n",
    "x = layers.Rescaling(scale=1./255)(inputs)\n",
    "\n",
    "x = layers.RandomCrop(160, 160)(x)\n",
    "x = layers.RandomFlip(mode=\"horizontal\")(x)\n",
    "\n",
    "if pretrained == 'VGG16':\n",
    "    pt_model = applications.VGG16(weights='imagenet', include_top=False,      \n",
    "                                  input_tensor=x)\n",
    "    finetuning_first_trainable_layer = \"block5_conv1\" \n",
    "elif pretrained == 'MobileNet':\n",
    "    pt_model = applications.MobileNet(weights='imagenet', include_top=False,\n",
    "                                      input_tensor=x)\n",
    "    finetuning_first_trainable_layer = \"conv_dw_12\"\n",
    "else:\n",
    "    assert 0, \"Unknown model: \"+pretrained\n",
    "    \n",
    "pt_name = pt_model.name\n",
    "print('Using \"{}\" pre-trained model with {} layers'.format(pt_name,\n",
    "                                                           len(pt_model.layers)))\n",
    "\n",
    "for layer in pt_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then stack our own, randomly initialized layers on top of the pre-trained network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Flatten()(pt_model.output)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs,\n",
    "                    name=\"dvc-\"+pt_name+\"-reuse\")\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, 'tf2-dvc-'+pt_name+'-reuse.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning 1: New layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join(os.getcwd(), \"logs\",\n",
    "                      \"dvc_tfr-\"+pt_name+\"-reuse-\"+datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "print('TensorBoard log directory:', logdir)\n",
    "os.makedirs(logdir)\n",
    "callbacks = [TensorBoard(log_dir=logdir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "history = model.fit(train_dataset, epochs=epochs, \n",
    "                    validation_data=validation_dataset,\n",
    "                    callbacks=callbacks, verbose=2)\n",
    "\n",
    "model.save(\"dvc_tfr-\" + pt_name + \"-reuse.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,3))\n",
    "\n",
    "ax1.plot(history.epoch,history.history['loss'], label='training')\n",
    "ax1.plot(history.epoch,history.history['val_loss'], label='validation')\n",
    "ax1.set_title('loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.legend(loc='best')\n",
    "\n",
    "ax2.plot(history.epoch,history.history['accuracy'], label='training')\n",
    "ax2.plot(history.epoch,history.history['val_accuracy'], label='validation')\n",
    "ax2.set_title('accuracy')\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "scores = model.evaluate(test_dataset, verbose=2)\n",
    "print(\"Test set %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning 2: Fine-tuning\n",
    "\n",
    "Once the top layers have learned some reasonable weights, we can continue training by unfreezing the last blocks of the pre-trained network so that it may adapt to our data. The learning rate should be smaller than usual. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name, \"trainable:\", layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_layer = False\n",
    "for layer in model.layers:\n",
    "    if layer.name == finetuning_first_trainable_layer:\n",
    "        train_layer = True\n",
    "    layer.trainable = train_layer\n",
    "    \n",
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name, \"trainable:\", layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "    optimizer=optimizers.RMSprop(learning_rate=1e-5),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join(os.getcwd(), \"logs\",\n",
    "                      \"dvc_tfr-\"+pt_name+\"-finetune-\"+datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "print('TensorBoard log directory:', logdir)\n",
    "os.makedirs(logdir)\n",
    "callbacks = [TensorBoard(log_dir=logdir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "history = model.fit(train_dataset, epochs=epochs, \n",
    "                    validation_data=validation_dataset,\n",
    "                    callbacks=callbacks, verbose=2)\n",
    "\n",
    "model.save(\"dvc_tfr-\" + pt_name + \"-finetune.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,3))\n",
    "\n",
    "ax1.plot(history.epoch,history.history['loss'], label='training')\n",
    "ax1.plot(history.epoch,history.history['val_loss'], label='validation')\n",
    "ax1.set_title('loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.legend(loc='best')\n",
    "\n",
    "ax2.plot(history.epoch,history.history['accuracy'], label='training')\n",
    "ax2.plot(history.epoch,history.history['val_accuracy'], label='validation')\n",
    "ax2.set_title('accuracy')\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "scores = model.evaluate(test_dataset, verbose=2)\n",
    "print(\"Test set %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.7",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
