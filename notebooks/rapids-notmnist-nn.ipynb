{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# notMNIST letters classification with nearest neighbors \n",
    "\n",
    "In this notebook, we'll use [nearest-neighbor classifiers](https://docs.rapids.ai/api/cuml/stable/api.html#id18) to classify notMNIST letters using a GPU and the [RAPIDS](https://rapids.ai/) libraries (cudf, cuml).\n",
    "\n",
    "**Note that a GPU is required with this notebook.**\n",
    "\n",
    "This version of the notebook has been tested with RAPIDS version 0.15.\n",
    "\n",
    "First, the needed imports. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pml_utils import show_failures, get_notmnist\n",
    "\n",
    "import cudf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "import cuml.neighbors\n",
    "from cuml import __version__ as cuml_version\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn import __version__ as sklearn_version\n",
    "import sklearn.neighbors\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "print('Using cudf version:', cudf.__version__)\n",
    "print('Using cuml version:', cuml_version)\n",
    "print('Using sklearn version:', sklearn_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we load the notMNIST data. First time we need to download the data, which can take a while. The data is stored as Numpy arrays in host (CPU) memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load notMNIST\n",
    "DATA_DIR = os.path.expanduser('~/data/notMNIST/')\n",
    "\n",
    "X_train, y_train, X_test, y_test = get_notmnist(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print('notMNIST data loaded: train:',len(X_train),'test:',len(X_test))\n",
    "print('X_train:', type(X_train), 'shape:', X_train.shape)\n",
    "print('y_train:', type(y_train), 'shape:', y_train.shape, y_train.dtype)\n",
    "print('X_test:', type(X_test), 'shape:', X_test.shape)\n",
    "print('y_test:', type(y_test), 'shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data (`X_train`) is a matrix of size (529114, 784), i.e. it consists of 529114 letters expressed as 784 sized vectors (28x28 images flattened to 1D). `y_train` is a 529114-dimensional vector containing the correct class (i.e. one of: \"A\", \"B\", ..., \"J\") for each training letter.\n",
    "\n",
    "Let's take a closer look. Here are the first 10 training letters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pltsize=1\n",
    "plt.figure(figsize=(10*pltsize, pltsize))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1,10,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X_train[i,:].reshape(28, 28), cmap=\"gray\")\n",
    "    plt.title('Class: '+y_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-NN classifier with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization\n",
    "\n",
    "Let's create first a 1-NN classifier with Scikit-learn, using CPU only.  Note that with nearest-neighbor classifiers there is no internal (parameterized) model and therefore no learning required.  Instead, calling the `fit()` function simply stores the samples of the training data in a suitable data structure.  Unfortunately, the dataset is so large that simply creating the data structure is still quite slow on the CPU. Therefore, we limit the training set to 50,000 items so we won't have to wait for too long..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "n_neighbors = 1\n",
    "clf_nn = sklearn.neighbors.KNeighborsClassifier(n_neighbors)\n",
    "clf_nn.fit(X_train[:50000], y_train[:50000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "And try to classify some test samples with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pred_nn = clf_nn.predict(X_test[:200,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the classifier is rather slow, and classifying the whole test set would take quite some time. What is the reason for this?\n",
    "\n",
    "The accuracy of the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print('Predicted', len(pred_nn), 'digits with accuracy:',\n",
    "      accuracy_score(y_test[:len(pred_nn)], pred_nn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-NN classifier with RAPIDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to convert our training and test data to cuDF DataFrames in device (GPU) memory. We will also convert the classes in `y_train` to integers in \n",
    "$[0 \\mathrel{{.}\\,{.}} 9]$.\n",
    "\n",
    "We will later evaluate the test data as Numpy arrays, so we do not need to convert `y_test`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cu_X_train = cudf.DataFrame.from_pandas(pd.DataFrame(X_train))\n",
    "cu_y_train = cudf.DataFrame.from_pandas(pd.DataFrame(y_train.view(np.int32)-ord('A')))\n",
    "cu_X_test  = cudf.DataFrame.from_pandas(pd.DataFrame(X_test))\n",
    "\n",
    "print('cu_X_train:', type(cu_X_train), 'shape:', cu_X_train.shape)\n",
    "print('cu_y_train:', type(cu_y_train), 'shape:', cu_y_train.shape)\n",
    "print('cu_X_test:', type(cu_X_test), 'shape:', cu_X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization\n",
    "\n",
    "Now, let's create the 1-NN classifier with RAPIDS, using the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "n_neighbors = 1\n",
    "cu_clf = cuml.neighbors.KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "cu_clf.fit(cu_X_train, cu_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "We can now classify the test samples with our classifier. With a GPU, classifying all samples should be rather fast. \n",
    "\n",
    "We also convert the predictions to a Numpy array in host memory with `values_host`. To match `y_test`, we also convert the predicted integer classes back to letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "predictions = cu_clf.predict(cu_X_test).values_host.flatten()\n",
    "predictions = [chr(x) for x in predictions+ord('A')]\n",
    "predictions = np.array(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print('Predicted', len(predictions), 'letters with accuracy:', \n",
    "      accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix\n",
    "\n",
    "We can compute the confusion matrix to see which digits get mixed the most:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "labels=['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']\n",
    "print('Confusion matrix (rows: true classes; columns: predicted classes):'); print()\n",
    "cm=confusion_matrix(y_test, predictions, labels=labels)\n",
    "print(cm); print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotted as an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(cm, cmap=plt.cm.gray)\n",
    "plt.xticks(range(10), labels)\n",
    "plt.yticks(range(10), labels)\n",
    "plt.grid(None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy, precision and recall\n",
    "\n",
    "Classification accuracy for each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for i,j in enumerate(cm.diagonal()/cm.sum(axis=1)): print(\"%s: %.4f\" % (labels[i],j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision and recall for each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions, labels=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Failure analysis\n",
    "\n",
    "We can also inspect the results in more detail. Let's use the `show_failures()` helper function (defined in `pml_utils.py`) to show the wrongly classified test digits.\n",
    "\n",
    "The helper function is defined as:\n",
    "\n",
    "```\n",
    "show_failures(predictions, y_test, X_test, trueclass=None, predictedclass=None, maxtoshow=10)\n",
    "```\n",
    "\n",
    "where:\n",
    "- `predictions` is a vector with the predicted classes for each test set image\n",
    "- `y_test` the _correct_ classes for the test set images\n",
    "- `X_test` the test set images\n",
    "- `trueclass` can be set to show only images for a given correct (true) class\n",
    "- `predictedclass` can be set to show only images which were predicted as a given class\n",
    "- `maxtoshow` specifies how many items to show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "show_failures(predictions, y_test, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `show_failures()` to inspect failures in more detail. For example:\n",
    "\n",
    "* show failures in which the true class was \"F\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "show_failures(predictions, y_test, X_test, trueclass='F')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* show failures in which the prediction was \"A\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "show_failures(predictions, y_test, X_test, predictedclass='A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* show failures in which the true class was \"A\" and the prediction was \"C\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "show_failures(predictions, y_test, X_test, trueclass='A', predictedclass='C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model tuning\n",
    "\n",
    "Try to modify the nearest-neighbor classifier. Things to try include using more than one neighbor and adding weights to the neighbors (if supported).  See the documentation for cuml [KNeighborsClassifier](https://docs.rapids.ai/api/cuml/stable/api.html#id18)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids",
   "language": "python",
   "name": "rapids"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
