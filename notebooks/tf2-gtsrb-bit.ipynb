{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic sign classification with BiT\n",
    "\n",
    "In this notebook, we'll finetune a [BigTransfer](https://arxiv.org/abs/1912.11370) (BiT) model from [TensorFlow Hub](https://tfhub.dev/) to classify images of traffic signs from [The German Traffic Sign Recognition Benchmark](http://benchmark.ini.rub.de/?section=gtsrb&subsection=news) using TensorFlow 2 / Keras. This notebook is somewhat based on the Keras code example [Image Classification using BigTransfer (BiT)](https://keras.io/examples/vision/bit/) by Sayan Nath.\n",
    "\n",
    "**Note that using a GPU with this notebook is highly recommended.**\n",
    "\n",
    "First, the needed imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os, datetime\n",
    "import pathlib\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import applications, optimizers\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from PIL import Image\n",
    "\n",
    "print('Using Tensorflow version:', tf.__version__,\n",
    "      'Keras version:', tf.keras.__version__,\n",
    "      'backend:', tf.keras.backend.backend())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The training dataset consists of 5535 images of traffic signs of varying size. There are 43 different types of traffic signs:\n",
    "\n",
    "![title](imgs/gtsrb-montage.png)\n",
    "\n",
    "The validation and test sets consist of 999 and 12630 images, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"/media/data/gtsrb/train-5535/\"\n",
    "nimages = {'train':5535, 'validation':999, 'test':12630}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image paths and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths(dataset):\n",
    "    data_root = pathlib.Path(datapath+dataset)\n",
    "    image_paths = list(data_root.glob('*/*'))\n",
    "    image_paths = [str(path) for path in image_paths]\n",
    "    image_count = len(image_paths)\n",
    "    assert image_count == nimages[dataset], \"Found {} images, expected {}\".format(image_count, nimages[dataset])\n",
    "    return image_paths\n",
    "\n",
    "image_paths = dict()\n",
    "image_paths['train'] = get_paths('train')\n",
    "image_paths['validation'] = get_paths('validation')\n",
    "image_paths['test'] = get_paths('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = sorted(item.name for item in pathlib.Path(datapath+'train').glob('*/') if item.is_dir())\n",
    "label_to_index = dict((name, index) for index,name in enumerate(label_names))\n",
    "\n",
    "def get_labels(dataset):\n",
    "    return [label_to_index[pathlib.Path(path).parent.name]\n",
    "            for path in image_paths[dataset]]\n",
    "    \n",
    "image_labels = dict()\n",
    "image_labels['train'] = get_labels('train')\n",
    "image_labels['validation'] = get_labels('validation')\n",
    "image_labels['test'] = get_labels('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data loading\n",
    "\n",
    "We now define a function to load the images. The images are in PPM format, so we use the PIL library. Also we need to resize the images to a fixed size (`INPUT_IMAGE_SIZE`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUT_IMAGE_SIZE = [80, 80]\n",
    "\n",
    "def _load_image(path, label):\n",
    "    image = Image.open(path.numpy())\n",
    "    return np.array(image), label\n",
    "\n",
    "def load_image(path, label):\n",
    "    image, label = tf.py_function(_load_image, (path, label), (tf.float32, tf.int32))\n",
    "    image.set_shape([None, None, None])\n",
    "    label.set_shape([])\n",
    "    return tf.image.resize(image, INPUT_IMAGE_SIZE), label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TF Datasets\n",
    "\n",
    "Let's now define our [TF `Dataset`s](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset#class_dataset) for training, validation, and test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((image_paths['train'],\n",
    "                                                    image_labels['train']))\n",
    "train_dataset = train_dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(2000).batch(BATCH_SIZE, drop_remainder=True)\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((image_paths['validation'],\n",
    "                                                         image_labels['validation']))\n",
    "validation_dataset = validation_dataset.map(load_image,\n",
    "                                            num_parallel_calls=tf.data.AUTOTUNE)\n",
    "validation_dataset = validation_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((image_paths['test'],\n",
    "                                                   image_labels['test']))\n",
    "test_dataset = test_dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see a couple of our training images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for batch, labels in train_dataset.take(1):\n",
    "    for i in range(9):    \n",
    "        plt.subplot(3,3,i+1)\n",
    "        plt.imshow(tf.cast(batch[i,:,:,:], tf.int32))\n",
    "        plt.title(label_names[labels[i]])\n",
    "        plt.grid(False)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.suptitle('some training images', fontsize=16, y=0.93)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiT\n",
    "\n",
    "### Initialization\n",
    "\n",
    "Now we specify the pre-trained BiT model we are going to use. The model [\"BiT-M R50x1\"](https://tfhub.dev/google/bit/m-r50x1/1) is pre-trained on ImageNet-21k (14 million images, 21,843 classes). It outputs 2048-dimensional feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_model_url = \"https://tfhub.dev/google/bit/m-r50x1/1\"\n",
    "bit_model = hub.KerasLayer(bit_model_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll apply random augmentation transformations (small random crop and contrast adjustment) to them each time we are looping over them. This way, we \"augment\" our training dataset to contain more data. The augmentation transformations are implemented as preprocessing layers in Keras. There are various such layers readily available, see [https://keras.io/guides/preprocessing_layers/](https://keras.io/guides/preprocessing_layers/) for more information.\n",
    "\n",
    "Then we add the BiT model as a layer and finally add the output layer with 43 units and softmax activation. Note that we initialize the output layer to all zeroes as instructed in https://keras.io/examples/vision/bit/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=INPUT_IMAGE_SIZE+[3])\n",
    "x = layers.Rescaling(scale=1./255)(inputs)\n",
    "\n",
    "x = layers.RandomCrop(75, 75)(x)\n",
    "x = layers.RandomContrast(0.1)(x)\n",
    "\n",
    "x = bit_model(x)\n",
    "\n",
    "outputs = layers.Dense(43, kernel_initializer=\"zeros\",\n",
    "                       activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs,\n",
    "                    name=\"gtsrb-bit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate, momentum = 0.003, 0.9\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=learning_rate,\n",
    "                                 momentum=momentum)\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "model.compile(loss=loss_fn, optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, 'tf2-gtsrb-bit.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning\n",
    "\n",
    "We'll set up two callbacks. *EarlyStopping* is used to stop training when the monitored metric has stopped improving. *TensorBoard* is used to visualize our progress during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join(\n",
    "    os.getcwd(), \"logs\",\n",
    "    \"gtsrb-bit-\"+datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "print('TensorBoard log directory:', logdir)\n",
    "os.makedirs(logdir)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\", patience=4, restore_best_weights=True),\n",
    "    TensorBoard(log_dir=logdir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "history = model.fit(train_dataset, batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=validation_dataset,\n",
    "                    callbacks=callbacks)\n",
    "model.save(\"gtsrb-bit.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,3))\n",
    "\n",
    "ax1.plot(history.epoch,history.history['loss'], label='training')\n",
    "ax1.plot(history.epoch,history.history['val_loss'], label='validation')\n",
    "ax1.set_title('loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.legend(loc='best')\n",
    "\n",
    "ax2.plot(history.epoch,history.history['accuracy'], label='training')\n",
    "ax2.plot(history.epoch,history.history['val_accuracy'], label='validation')\n",
    "ax2.set_title('accuracy')\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "scores = model.evaluate(test_dataset, verbose=2)\n",
    "print(\"Test set %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.7",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
