{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2edd322b-1e0a-4fc4-919b-e808ad472cfe",
   "metadata": {},
   "source": [
    "# IMDB movie review sentiment classification using Hugging Face models\n",
    "\n",
    "In this notebook, we'll test pre-trained sentiment analysis models and later finetune a DistilBERT model to perform IMDB movie review sentiment classification. This notebook is adapted from [Getting Started with Sentiment Analysis using Python](https://huggingface.co/blog/sentiment-analysis-python)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9243fc9-da3f-470d-9e0f-9aaa9528efcd",
   "metadata": {},
   "source": [
    "Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1227c62-d120-4908-8d35-6bf0f236be50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "from huggingface_hub import notebook_login\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35124c9a-1f07-416b-834d-f9c7508f682c",
   "metadata": {},
   "source": [
    "Check if PyTorch is using the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b124df20-1f8a-4a5e-9975-4798bfdaf0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Using PyTorch version:', torch.__version__)\n",
    "if torch.cuda.is_available():\n",
    "    print('Using GPU, device name:', torch.cuda.get_device_name(0))\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print('No GPU found, using CPU instead.') \n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5800ebf-82bd-4cdc-9067-66ee8480d528",
   "metadata": {},
   "source": [
    "## Use Pre-trained Sentiment Analysis Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c82b0f7-62d8-4e3f-9e99-ef3ebc6522bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_pipeline = pipeline(\"sentiment-analysis\",device=device)\n",
    "data = [\"I love you\", \"I hate you\"]\n",
    "sentiment_pipeline(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97a94f5-1548-46f2-a2f9-1715113e90ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "- This code snippet above utilizes the **[pipeline](https://huggingface.co/docs/transformers/main_classes/pipelines)** class to generate predictions using models from the Hub. It applies the [default sentiment analysis model](https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english) to evaluate the provided list of text data.\n",
    "- The analysis results are **POSITIVE** for first entry and **NEGATIVE** for the second entry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c273d882-0aa9-4d86-a1fa-fd518e2c3ce0",
   "metadata": {},
   "source": [
    "One can also use a specific sentiment analysis model by providing the name of the model, e.g., if you want a sentiment analysis model for tweets, you can specify the model id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c183b485-adc5-447d-b3b7-bb66e173c80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_model = pipeline(model=\"finiteautomata/bertweet-base-sentiment-analysis\", device = device)\n",
    "specific_model(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf45bd1-3964-4d32-944b-edd0783163bb",
   "metadata": {},
   "source": [
    "## Fine-tuning DistilBERT model using IMDB dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec252bb-b0b0-48dc-8e3a-b65b72f931c1",
   "metadata": {},
   "source": [
    "- The [IMDB](https://huggingface.co/datasets/stanfordnlp/imdb) dataset contains 50000 movies reviews from the Internet Movie Database, split into 25000 reviews for training and 25000 reviews for testing. Half of the reviews are positive and half are negative. \n",
    "\n",
    "- The IMDB dataset is relatively large, so let's use 5000 samples for training to speed up our process for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bb7a7d-9194-4904-bc91-bd1adb191ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = load_dataset(\"imdb\")\n",
    "small_train_dataset = imdb[\"train\"].shuffle(seed=0).select([i for i in list(range(5000))])\n",
    "test_dataset = imdb[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fe9183-d554-482c-8f3a-a75096e10e14",
   "metadata": {},
   "source": [
    "To preprocess our data, we will use DistilBERT tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf1e5fc-3831-47d0-ab3f-01d6dd70482a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e45582-a0c3-4a80-8a06-d4ce232a1ead",
   "metadata": {},
   "source": [
    "- Next, we will prepare the text inputs for the model for both splits of our dataset (training and test) by using the map method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab50bd2-e54b-4e31-a162-24923b763731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "   return tokenizer(examples[\"text\"], truncation=True)\n",
    " \n",
    "tokenized_train = small_train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_test = test_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b9b4c0-9aea-481b-bb26-5f9bd18228c1",
   "metadata": {},
   "source": [
    "- To speed up training, let's use a data_collator to convert your training samples to PyTorch tensors and concatenate them with the correct amount of padding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10d80c5-77c3-43a6-a7d9-47d97deef882",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0455d055-7b18-47a2-b983-e7a35e46398f",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "- We will be throwing away the pretraining head of the DistilBERT model and replacing it with a classification head fine-tuned for sentiment analysis. This enables us to transfer the knowledge from DistilBERT to our custom model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1644ded6-7d6a-43d2-b303-3d43eb316e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6577793-6f3d-48a3-b13e-95116be72685",
   "metadata": {},
   "source": [
    "- Then, let's define the metrics you will be using to evaluate how good is your fine-tuned model (accuracy and f1 score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81da7601-9ca0-45ee-94f8-d9d773fff695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "   load_accuracy = load_metric(\"accuracy\")\n",
    "   load_f1 = load_metric(\"f1\")\n",
    "  \n",
    "   logits, labels = eval_pred\n",
    "   predictions = np.argmax(logits, axis=-1)\n",
    "   accuracy = load_accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "   f1 = load_f1.compute(predictions=predictions, references=labels)[\"f1\"]\n",
    "   return {\"accuracy\": accuracy, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad53c65b-3463-4707-a8ad-ebd2de387133",
   "metadata": {},
   "source": [
    "- Define the training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b56df8-a9ac-41ec-9ad7-86c0e0cec2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_name = \"finetuning-sentiment-model-5000-samples\"\n",
    " \n",
    "training_args = TrainingArguments(\n",
    "   output_dir=repo_name,\n",
    "   learning_rate=2e-5,\n",
    "   per_device_train_batch_size=16,\n",
    "   per_device_eval_batch_size=16,\n",
    "   num_train_epochs=2,\n",
    "   weight_decay=0.01,\n",
    "   save_strategy=\"epoch\",\n",
    "   push_to_hub=False,\n",
    ")\n",
    " \n",
    "trainer = Trainer(\n",
    "   model=model,\n",
    "   args=training_args,\n",
    "   train_dataset=tokenized_train,\n",
    "   eval_dataset=tokenized_test,\n",
    "   tokenizer=tokenizer,\n",
    "   data_collator=data_collator,\n",
    "   compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaad4946-5446-4cd1-ae2f-8502d2e3037f",
   "metadata": {},
   "source": [
    "- Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53f771c-d1fb-4a5b-a426-ae5bd53964df",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3eee23-b26c-4687-8d27-7d075d76d3a9",
   "metadata": {},
   "source": [
    "- Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a951518-0ee7-4e73-b47b-f679b7e6e628",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61722a1b-3347-469c-b0d9-89398e4601ca",
   "metadata": {},
   "source": [
    "- Model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3db7322-4f03-4fd2-996b-948e3c271da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-classification\", model=model,tokenizer=tokenizer, device = device)\n",
    "pipe([\"I love this move\", \"This movie sucks!\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d40ac81-bf5b-4ab7-b713-61fd22151020",
   "metadata": {},
   "source": [
    "## Task 1 Run this script with GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8eb61e-a673-4b22-8c6d-7262946964f6",
   "metadata": {},
   "source": [
    "## Task 2 Compare the test dataset accuracy achieved from finetuned DistilBERT model and the previous RNN model. What do you notice?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
