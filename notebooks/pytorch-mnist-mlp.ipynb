{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST handwritten digits classification with MLPs\n",
    "\n",
    "In this notebook, we'll train a multi-layer perceptron model to classify MNIST digits using **PyTorch**. \n",
    "\n",
    "First, the needed imports. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "print('Using PyTorch version:', torch.__version__)\n",
    "if torch.cuda.is_available():\n",
    "    print('Using GPU, device name:', torch.cuda.get_device_name(0))\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print('No GPU found, using CPU instead.') \n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "PyTorch has two classes from [`torch.utils.data` to work with data](https://pytorch.org/docs/stable/data.html#module-torch.utils.data): \n",
    "- [Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) which represents the actual data items, such as images or pieces of text, and their labels\n",
    "- [DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) which is used for processing the dataset in batches in an efficient manner.\n",
    "\n",
    "PyTorch has domain-specific libraries with utilities for common data types such as [TorchText](https://pytorch.org/text/stable/index.html), [TorchVision](https://pytorch.org/vision/stable/index.html) and [TorchAudio](https://pytorch.org/audio/stable/index.html).\n",
    "\n",
    "Here we will use TorchVision and `torchvision.datasets` which provides easy access to [many common visual datasets](https://pytorch.org/vision/stable/datasets.html). In this example we'll use the [MNIST class](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST) which gives easy access to the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=ToTensor())\n",
    "test_dataset = datasets.MNIST('./data', train=False, transform=ToTensor())\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train and test data are provided via data loaders that provide iterators over the datasets. The first element of training data (`X_train`) is a 4th-order tensor of size (`batch_size`, 1, 28, 28), i.e. it consists of a batch of images of size 1x28x28 pixels. `y_train` is a vector containing the correct classes (\"0\", \"1\", ..., \"9\") for each training digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (X_train, y_train) in train_loader:\n",
    "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
    "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the first 10 training digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pltsize=1\n",
    "plt.figure(figsize=(10*pltsize, pltsize))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1,10,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X_train[i,:,:,:].numpy().reshape(28,28), cmap=\"gray_r\")\n",
    "    plt.title('Class: '+str(y_train[i].item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layer perceptron (MLP) network\n",
    "\n",
    "In PyTorch, a neural network is defined as a Python class. It needs to have two methods:\n",
    "\n",
    "- `__init__()` which initializes the layers used in the network\n",
    "- `forward()` which defines how the network performs a forward pass\n",
    "\n",
    "PyTorch will then automatically generate a `backward()` method that computes the gradients based on the computation done in the forward pass.\n",
    "\n",
    "All the [neural network building blocks defined in PyTorch can be found in the torch.nn documentation](https://pytorch.org/docs/stable/nn.html).\n",
    "\n",
    "We used the `nn.Sequential` to more easily create a simple sequental neural network:\n",
    "\n",
    "- First we need to \"flatten\" the 2D image into a vector with `nn.Flatten`\n",
    "\n",
    "- Next a fully-connected layer with 20 neurons is created with `nn.Linear`. Note that we need to specify the number on input and output connections. In this case there are 28x28=784 inputs, and 20 outputs\n",
    "\n",
    "- Next, a ReLU non-linear activation\n",
    "\n",
    "- Finally the output of the last layer needs to a 10-dimensional vector to match the ground truth of ten classes (the ten digits).\n",
    "\n",
    "The output of the last layer should be normalized with softmax, but this is actually included implicitly in the loss function in PyTorch (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "model = Net().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model\n",
    "\n",
    "In order to train the model we need to define a loss function and an optimizer.\n",
    "\n",
    "For a classification task we typically use the cross entropy loss. For this we can use the class [CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html).\n",
    "\n",
    "**Note:** if you read the documentation of `CrossEntropyLoss` carefully you will see that \"[t]he input is expected to contain the unnormalized logits for each class\", which is why we don't need to explicitly use softmax in the network definition above.\n",
    "\n",
    "Finally, we need to define an optimizer, which tells how to update the model parameters based on the computed gradients. There are [several different optimizer algorithms implemented in PyTorch](https://pytorch.org/docs/stable/optim.html#algorithms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch we have to write the training loop ourselves.\n",
    "\n",
    "We'll train for several *epochs*, an *epoch* is a single pass through the whole training data.\n",
    "\n",
    "The code below consists of two loops:\n",
    "\n",
    "- The outer loop goes over a number of *epochs*. An epoch is a single pass through the whole training data.\n",
    "- The inner loop goes through the whole dataset once, a batch at a time. Here we have defined the batch size to be 32, so images are handled 32 at a time.\n",
    "\n",
    "For each batch we:\n",
    "\n",
    "- Copy the data to the GPU with the `.to(device)` method. If we don't have a GPU, these commands will not do anything.\n",
    "\n",
    "- Doing a forward pass is as simple as passing the `data` through the `model` and collecting the `output`\n",
    "\n",
    "- Finally we calculate the loss - that is the error between the output of the network and the target we want to get - using the `criterion` function we defined earlier\n",
    "\n",
    "- The last lines do the backward propagation with `loss.backward()`, the weights are updated with `optimizer.step()` and finally we need to zero the gradient counters with `optimizer.zero_grad()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 10\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    num_batches = len(train_loader)\n",
    "    train_loss = 0\n",
    "    for batch, (data, target) in tqdm(enumerate(train_loader), \n",
    "                                      desc=f\"Epoch {epoch+1}\", \n",
    "                                      total=num_batches):\n",
    "        # Copy data and targets to GPU\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        # Do a forward pass\n",
    "        output = model(data)\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        train_loss += loss\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    train_loss = train_loss/num_batches\n",
    "    print(f\"avg loss: {train_loss:>7f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "For a better measure of the quality of the model, let's see the model accuracy for the test data.\n",
    "\n",
    "The code is similar to the training code: we just loop over the whole testset. We just set the model to \"eval\" mode and use `torch.no_grad()` to tell PyTorch it doesn't need to calculate any gradients this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "num_batches = len(test_loader)\n",
    "num_items = len(test_loader.dataset)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in tqdm(test_loader, desc=\"Inference\", total=num_batches):\n",
    "        # Copy data and targets to GPU\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        # Do a forward pass\n",
    "        output = model(data)\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        correct += (output.argmax(1) == target).type(torch.float).sum().item()\n",
    "        \n",
    "test_loss = test_loss/num_batches\n",
    "accuracy = correct/num_items\n",
    "\n",
    "print(f\"Testset accuracy: {100*accuracy:>0.1f}%, avg loss: {avg_loss:>7f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model tuning\n",
    "\n",
    "Modify the MLP model.  Try to improve the classification accuracy, or experiment with the effects of different parameters.  If you are interested in the state-of-the-art performance on permutation invariant MNIST, see e.g. [this paper](https://arxiv.org/abs/1507.02672) by Aalto University / The Curious AI Company researchers.\n",
    "\n",
    "You can also consult the PyTorch documentation at http://pytorch.org/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*Run this notebook in Google Colaboratory using [this link](https://colab.research.google.com/github/csc-training/intro-to-dl/blob/master/day1/optional/pytorch-mnist-mlp.ipynb).*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
