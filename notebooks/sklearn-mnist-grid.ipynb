{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# MNIST handwritten digits classification with parameter grid search for SVM\n",
    "\n",
    "In this notebook, we'll use [grid search](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) and a validation set to find optimal values for our SVM model's hyperparameters.\n",
    "\n",
    "First, the needed imports. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import svm, datasets, __version__\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# Suppress annoying warnings...\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "from distutils.version import LooseVersion as LV\n",
    "assert(LV(__version__) >= LV(\"0.20\")), \"Version >= 0.20 of sklearn is required.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Then we load the MNIST data. First time it downloads the data, which can take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "mnist = datasets.fetch_openml('mnist_784')\n",
    "\n",
    "train_len = 60000\n",
    "X = mnist['data']\n",
    "y = mnist['target']\n",
    "\n",
    "X_train, y_train = X[:train_len], y[:train_len]\n",
    "X_test, y_test = X[train_len:], y[train_len:]     \n",
    "     \n",
    "print('MNIST data loaded: train:',len(X_train),'test:',len(X_test))\n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test', X_test.shape)\n",
    "print('y_test', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Linear SVM\n",
    "\n",
    "Let's start with the linear SVM trained with a subset of training data.  `C` is the penalty parameter that we need to specify.  Let's first try with just some guess, e.g., `C=1.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "clf_lsvm = svm.LinearSVC(C=1.0)\n",
    "\n",
    "print(clf_lsvm.fit(X_train[:10000,:], y_train[:10000]))\n",
    "\n",
    "pred_lsvm = clf_lsvm.predict(X_test)\n",
    "print('Predicted', len(pred_lsvm), 'digits with accuracy:', accuracy_score(y_test, pred_lsvm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Next, let's try grid search, i.e., we try several different values for the parameter `C`.  Remember that it's important to *not* use the test set for evaluating hyperparameters.  Instead we opt to set aside the last 1000 images as a validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# The values for C that we will try out\n",
    "param_grid = {'C': [1, 10, 100, 1000]}\n",
    "\n",
    "# Use first 9000 as training and last 1000 as vaildation set\n",
    "valid_split = PredefinedSplit(9000*[-1] + 1000*[0])\n",
    "\n",
    "clf_lsvm_grid = GridSearchCV(clf_lsvm, param_grid, cv=valid_split, verbose=2)\n",
    "print(clf_lsvm_grid.fit(X_train[:10000,:], y_train[:10000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We can now see what was the best value for C that was selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(clf_lsvm_grid.best_params_)\n",
    "\n",
    "best_C = clf_lsvm_grid.best_params_['C']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Let's try predicting with out new model with optimal hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "clf_lsvm2 = svm.LinearSVC(C=best_C)\n",
    "\n",
    "print(clf_lsvm2.fit(X_train[:10000,:], y_train[:10000]))\n",
    "\n",
    "pred_lsvm2 = clf_lsvm2.predict(X_test)\n",
    "print('Predicted', len(pred_lsvm2), 'digits with accuracy:', accuracy_score(y_test, pred_lsvm2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Kernel SVM\n",
    "\n",
    "The Kernel SVM typically has two hyperparameters that need to be set.  For example for a Gaussian (or RBF) kernel we also have `gamma` (Greek $\\gamma$) in addition to `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "clf_ksvm = svm.SVC(decision_function_shape='ovr', kernel='rbf', C=1.0, gamma=1e-6)\n",
    "print(clf_ksvm.fit(X_train[:10000,:], y_train[:10000]))\n",
    "\n",
    "pred_ksvm = clf_ksvm.predict(X_test)\n",
    "print('Predicted', len(pred_ksvm), 'digits with accuracy:', accuracy_score(y_test, pred_ksvm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Now we can try grid search again, now with two parameters.  We use even a smaller subset of the training set it will otherwise be too slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {'C': [1, 10, 100],\n",
    "              'gamma': [1e-8, 5e-8, 1e-7, 5e-7, 1e-6]}\n",
    "\n",
    "train_items = 3000\n",
    "valid_items = 500\n",
    "tot_items = train_items + valid_items\n",
    "\n",
    "# Use first 9000 as training and last 1000 as vaildation set\n",
    "valid_split = PredefinedSplit(train_items*[-1] + valid_items*[0])\n",
    "\n",
    "clf_ksvm_grid = GridSearchCV(clf_ksvm, param_grid, cv=valid_split, verbose=2)\n",
    "print(clf_ksvm_grid.fit(X_train[:tot_items,:], y_train[:tot_items]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Again, let's see what parameters were selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(clf_ksvm_grid.best_params_)\n",
    "\n",
    "best_C = clf_ksvm_grid.best_params_['C']\n",
    "best_gamma = clf_ksvm_grid.best_params_['gamma']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "As we did the grid search on a small subset of the training set it probably makes sense to retrain the model with the selected parameters using a bigger part of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "clf_ksvm2 = svm.SVC(decision_function_shape='ovr', kernel='rbf', C=best_C, gamma=best_gamma)\n",
    "print(clf_ksvm2.fit(X_train[:10000,:], y_train[:10000]))\n",
    "\n",
    "pred_ksvm2 = clf_ksvm2.predict(X_test)\n",
    "print('Predicted', len(pred_ksvm2), 'digits with accuracy:', accuracy_score(y_test, pred_ksvm2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "name": "sklearn-mnist-grid.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
