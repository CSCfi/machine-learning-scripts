{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs-vs-cats classification with BiT\n",
    "\n",
    "In this notebook, we'll finetune a [BigTransfer](https://arxiv.org/abs/1912.11370) (BiT) model from [TensorFlow Hub](https://tfhub.dev/) to classify images of dogs from images of cats using TensorFlow 2 / Keras. This notebook is somewhat based on the Keras code example [Image Classification using BigTransfer (BiT)](https://keras.io/examples/vision/bit/) by Sayan Nath.\n",
    "\n",
    "**Note that using a GPU with this notebook is highly recommended.**\n",
    "\n",
    "First, the needed imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os, datetime\n",
    "import pathlib\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import applications, optimizers\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "print('Using Tensorflow version:', tf.__version__,\n",
    "      'Keras version:', tf.keras.__version__,\n",
    "      'backend:', tf.keras.backend.backend())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The training dataset consists of 2000 images of dogs and cats, split in half.  In addition, the validation set consists of 1000 images, and the test set of 22000 images.  Here are some random training images:\n",
    "\n",
    "![title](imgs/dvc.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"/media/data/dogs-vs-cats/train-2000/\"\n",
    "nimages = {'train':2000, 'validation':1000, 'test':22000}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image paths and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths(dataset):\n",
    "    data_root = pathlib.Path(datapath+dataset)\n",
    "    image_paths = list(data_root.glob('*/*'))\n",
    "    image_paths = [str(path) for path in image_paths]\n",
    "    image_count = len(image_paths)\n",
    "    assert image_count == nimages[dataset], \"Found {} images, expected {}\".format(image_count, nimages[dataset])\n",
    "    return image_paths\n",
    "\n",
    "image_paths = dict()\n",
    "image_paths['train'] = get_paths('train')\n",
    "image_paths['validation'] = get_paths('validation')\n",
    "image_paths['test'] = get_paths('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = sorted(item.name for item in pathlib.Path(datapath+'train').glob('*/') if item.is_dir())\n",
    "label_to_index = dict((name, index) for index,name in enumerate(label_names))\n",
    "\n",
    "def get_labels(dataset):\n",
    "    return [label_to_index[pathlib.Path(path).parent.name]\n",
    "            for path in image_paths[dataset]]\n",
    "    \n",
    "image_labels = dict()\n",
    "image_labels['train'] = get_labels('train')\n",
    "image_labels['validation'] = get_labels('validation')\n",
    "image_labels['test'] = get_labels('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading\n",
    "\n",
    "We now define a function to load the images. Also we need to resize the images to a fixed size (`INPUT_IMAGE_SIZE`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_IMAGE_SIZE = [256, 256]\n",
    "\n",
    "def load_image(path, label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    return tf.image.resize(image, INPUT_IMAGE_SIZE), label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF Datasets\n",
    "\n",
    "Let's now define our [TF `Dataset`s](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset#class_dataset) for training, validation, and test data. First the Datasets contain the filenames of the images and the corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((image_paths['train'],\n",
    "                                                    image_labels['train']))\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((image_paths['validation'],\n",
    "                                                         image_labels['validation']))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((image_paths['test'],\n",
    "                                                   image_labels['test']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then `map()` the filenames to the actual image data and decode the images.\n",
    "Note that we shuffle the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataset = train_dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(2000).batch(BATCH_SIZE, drop_remainder=True)\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "validation_dataset = validation_dataset.map(load_image,\n",
    "                                            num_parallel_calls=tf.data.AUTOTUNE)\n",
    "validation_dataset = validation_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "test_dataset = test_dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see a couple of our training images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for batch, labels in train_dataset.take(1):\n",
    "    for i in range(9):    \n",
    "        plt.subplot(3,3,i+1)\n",
    "        plt.imshow(tf.cast(batch[i,:,:,:], tf.int32))\n",
    "        plt.title(label_names[labels[i]])\n",
    "        plt.grid(False)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.suptitle('some training images', fontsize=16, y=0.93)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiT\n",
    "\n",
    "### Initilization\n",
    "\n",
    "Now we specify the pre-trained BiT model we are going to use. The model [\"BiT-M R50x1\"](https://tfhub.dev/google/bit/m-r50x1/1) is pre-trained on ImageNet-21k (14 million images, 21,843 classes). It outputs 2048-dimensional feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_model_url = \"https://tfhub.dev/google/bit/m-r50x1/1\"\n",
    "bit_model = hub.KerasLayer(bit_model_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll apply random augmentation transformations (crop and horizontal flip) to them each time we are looping over them. This way, we \"augment\" our training dataset to contain more data. The augmentation transformations are implemented as preprocessing layers in Keras. There are various such layers readily available, see [https://keras.io/guides/preprocessing_layers/](https://keras.io/guides/preprocessing_layers/) for more information.\n",
    "\n",
    "Then we add the BiT model as a layer and finally add the output layer with a single unit and sigmoid activation. Note that we initialize the output layer to all zeroes as instructed in https://keras.io/examples/vision/bit/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=INPUT_IMAGE_SIZE+[3])\n",
    "x = layers.Rescaling(scale=1./255)(inputs)\n",
    "\n",
    "x = layers.RandomCrop(160, 160)(x)\n",
    "x = layers.RandomFlip(mode=\"horizontal\")(x)\n",
    "\n",
    "x = bit_model(x)\n",
    "\n",
    "outputs = layers.Dense(1, kernel_initializer=\"zeros\",\n",
    "                       activation='sigmoid')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs,\n",
    "                    name=\"dvc-bit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate, momentum = 0.003, 0.9\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=learning_rate,\n",
    "                                 momentum=momentum)\n",
    "loss_fn = keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "model.compile(loss=loss_fn, optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, 'tf2-dvc-bit.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning\n",
    "\n",
    "We'll set up two callbacks. *EarlyStopping* is used to stop training when the monitored metric has stopped improving. *TensorBoard* is used to visualize our progress during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join(\n",
    "    os.getcwd(), \"logs\",\n",
    "    \"dvc-bit-\"+datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "print('TensorBoard log directory:', logdir)\n",
    "os.makedirs(logdir)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\", patience=2, restore_best_weights=True),\n",
    "    TensorBoard(log_dir=logdir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "history = model.fit(train_dataset, batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=validation_dataset,\n",
    "                    callbacks=callbacks)\n",
    "model.save(\"dvc-bit.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,3))\n",
    "\n",
    "ax1.plot(history.epoch,history.history['loss'], label='training')\n",
    "ax1.plot(history.epoch,history.history['val_loss'], label='validation')\n",
    "ax1.set_title('loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.legend(loc='best')\n",
    "\n",
    "ax2.plot(history.epoch,history.history['accuracy'], label='training')\n",
    "ax2.plot(history.epoch,history.history['val_accuracy'], label='validation')\n",
    "ax2.set_title('accuracy')\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "scores = model.evaluate(test_dataset, verbose=2)\n",
    "print(\"Test set %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use TensorBoard to visualize our progress during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "callbacks = [TensorBoard(log_dir=logdir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "history = model.fit(train_dataset, epochs=epochs, \n",
    "                    validation_data=validation_dataset,\n",
    "                    callbacks=callbacks, verbose=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.7",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
