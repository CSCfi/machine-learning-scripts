{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jNKaJz5j_ylj"
   },
   "source": [
    "# 20 newsgroup text classification with BERT finetuning\n",
    "\n",
    "In this notebook, we'll use a pre-trained [BERT](https://arxiv.org/abs/1810.04805) model for text classification using TensorFlow 2 / Keras and HuggingFace's [Transformers](https://github.com/huggingface/transformers). This notebook is based on [\"Predicting Movie Review Sentiment with BERT on TF Hub\"](https://github.com/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb) by Google and [\"BERT Fine-Tuning Tutorial with PyTorch\"](https://mccormickml.com/2019/07/22/BERT-fine-tuning/) by Chris McCormick.\n",
    "\n",
    "**Note that using a GPU with this notebook is highly recommended.**\n",
    "\n",
    "First, the needed imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ok002ceNB8E7",
    "outputId": "06ef90d2-7518-4209-da66-1dd45c357c78"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import __version__ as transformers_version\n",
    "\n",
    "from distutils.version import LooseVersion as LV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import io, sys, os, datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "print('Using TensorFlow version:', tf.__version__,\n",
    "      'Keras version:', tf.keras.__version__,\n",
    "      'Transformers version:', transformers_version)\n",
    "assert(LV(tf.__version__) >= LV(\"2.3.0\"))\n",
    "\n",
    "if len(tf.config.list_physical_devices('GPU')):\n",
    "    from tensorflow.python.client import device_lib\n",
    "    for d in device_lib.list_local_devices():\n",
    "        if d.device_type == 'GPU':\n",
    "            print('GPU:', d.physical_device_desc)\n",
    "else:\n",
    "    print('No GPU, using CPU instead.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20 Newsgroups data set\n",
    "\n",
    "Next we'll load the [20 Newsgroups](http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.html) data set. \n",
    "\n",
    "The dataset contains 20000 messages collected from 20 different Usenet newsgroups (1000 messages from each group):\n",
    "\n",
    "|[]()|[]()|[]()|[]()|\n",
    "| --- | --- |--- | --- |\n",
    "| alt.atheism           | soc.religion.christian   | comp.windows.x     | sci.crypt |               \n",
    "| talk.politics.guns    | comp.sys.ibm.pc.hardware | rec.autos          | sci.electronics |              \n",
    "| talk.politics.mideast | comp.graphics            | rec.motorcycles    | sci.space |                   \n",
    "| talk.politics.misc    | comp.os.ms-windows.misc  | rec.sport.baseball | sci.med |                     \n",
    "| talk.religion.misc    | comp.sys.mac.hardware    | rec.sport.hockey   | misc.forsale |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_DATA_DIR = \"/media/data/20_newsgroup\"\n",
    "\n",
    "print('Processing text dataset')\n",
    "\n",
    "texts = []  # list of text samples\n",
    "labels_index = {}  # dictionary mapping label name to numeric id\n",
    "labels = []  # list of label ids\n",
    "for name in sorted(os.listdir(TEXT_DATA_DIR)):\n",
    "    path = os.path.join(TEXT_DATA_DIR, name)\n",
    "    if os.path.isdir(path):\n",
    "        label_id = len(labels_index)\n",
    "        labels_index[name] = label_id\n",
    "        for fname in sorted(os.listdir(path)):\n",
    "            if fname.isdigit():\n",
    "                fpath = os.path.join(path, fname)\n",
    "                args = {} if sys.version_info < (3,) else {'encoding': 'latin-1'}\n",
    "                with open(fpath, **args) as f:\n",
    "                    t = f.read()\n",
    "                    i = t.find('\\n\\n')  # skip header\n",
    "                    if 0 < i:\n",
    "                        t = t[i:]\n",
    "                    texts.append(t)\n",
    "                labels.append(label_id)\n",
    "\n",
    "labels = np.array(labels)\n",
    "print('Found %s texts.' % len(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data into training, validation, and test sets using scikit-learn's `train_test_split()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SET = 4000\n",
    "\n",
    "(texts_train, texts_test,\n",
    " labels_train, labels_test) = train_test_split(texts, labels, \n",
    "                                               test_size=TEST_SET,\n",
    "                                               shuffle=True, random_state=42)\n",
    "\n",
    "(texts_train, texts_valid,\n",
    " labels_train, labels_valid) = train_test_split(texts_train, labels_train, \n",
    "                                                shuffle=False,\n",
    "                                                test_size=0.1)\n",
    "\n",
    "print('Length of training texts:', len(texts_train), 'labels:', len(labels_train))\n",
    "print('Length of validation texts:', len(texts_valid), 'labels:', len(labels_valid))\n",
    "print('Length of test texts:', len(texts_test), 'labels:', len(labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BTREubVNFiz4"
   },
   "source": [
    "## BERT\n",
    "\n",
    "Next we specify the pre-trained BERT model we are going to use. The model `\"bert-base-uncased\"` is the lowercased \"base\" model (12-layer, 768-hidden, 12-heads, 110M parameters).\n",
    "\n",
    "### Tokenization\n",
    "\n",
    "We load the used vocabulary from the BERT model, and use the BERT tokenizer to convert the messages into tokens that match the data the BERT model was trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERTMODEL='bert-base-uncased'\n",
    "CACHE_DIR='/media/data/transformers-cache/'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(BERTMODEL,\n",
    "                                          do_lower_case=True,\n",
    "                                          cache_dir=CACHE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we tokenize all datasets. We set the maximum sequence lengths for our training and test messages as MAX_LEN_TRAIN and MAX_LEN_TEST. The maximum length supported by the used BERT model is 512 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "MAX_LEN_TRAIN, MAX_LEN_TEST = 128, 512\n",
    "\n",
    "data_train = tokenizer(texts_train, padding=True, truncation=True,\n",
    "                       return_tensors=\"tf\", max_length=MAX_LEN_TRAIN)\n",
    "data_valid = tokenizer(texts_valid, padding=True, truncation=True,\n",
    "                       return_tensors=\"tf\", max_length=MAX_LEN_TRAIN)\n",
    "data_test = tokenizer(texts_test, padding=True, truncation=True,\n",
    "                      return_tensors=\"tf\", max_length=MAX_LEN_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the truncated tokenized first training message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[\"input_ids\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also convert the token ids back to tokens. `[CLS]` and `[SEP]` are special tokens required by BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(data_train[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF Datasets\n",
    "\n",
    "Let's now define our TF `Dataset`s for training, validation, and test data. A batch size of 16 or 32 is often recommended for fine-tuning BERT on a specific task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices((data_train.data, labels_train))\n",
    "dataset_train = dataset_train.shuffle(len(dataset_train)).batch(BATCH_SIZE)\n",
    "dataset_valid = tf.data.Dataset.from_tensor_slices((data_valid.data, labels_valid))\n",
    "dataset_valid = dataset_valid.batch(BATCH_SIZE)\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices((data_test.data, labels_test))\n",
    "dataset_test = dataset_test.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "gFsCTp_mporB",
    "outputId": "dd067229-1925-4b37-f517-0c14e25420d1"
   },
   "source": [
    "### Model initialization\n",
    "\n",
    "We now load a pretrained BERT model with a single linear classification layer added on top. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "gFsCTp_mporB",
    "outputId": "dd067229-1925-4b37-f517-0c14e25420d1"
   },
   "outputs": [],
   "source": [
    "model = TFBertForSequenceClassification.from_pretrained(BERTMODEL,\n",
    "                                                        cache_dir=CACHE_DIR,\n",
    "                                                        num_labels=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8o-VEBobKwHk"
   },
   "source": [
    "We use Adam as the optimizer, categorical crossentropy as loss, and then compile the model.\n",
    "\n",
    "`LR` is the learning rate for the Adam optimizer (2e-5 to 5e-5 recommended for BERT finetuning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 2e-5\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LR, epsilon=1e-08, clipnorm=1.0)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join(os.getcwd(), \"logs\",\n",
    "                      \"20ng-bert-\"+datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "print('TensorBoard log directory:', logdir)\n",
    "os.makedirs(logdir)\n",
    "callbacks = [TensorBoard(log_dir=logdir)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For fine-tuning BERT on a specific task, 2-4 epochs is often recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "EPOCHS = 4\n",
    "\n",
    "history = model.fit(dataset_train, validation_data=dataset_valid,\n",
    "                    epochs=EPOCHS, verbose=2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1-G03mmwH3aI"
   },
   "source": [
    "Let's take a look at loss and accuracy for train and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,3))\n",
    "\n",
    "ax1.plot(history.epoch,history.history['loss'], label='training')\n",
    "ax1.plot(history.epoch,history.history['val_loss'], label='validation')\n",
    "ax1.set_title('loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.legend(loc='best')\n",
    "\n",
    "ax2.plot(history.epoch,history.history['accuracy'], label='training')\n",
    "ax2.plot(history.epoch,history.history['val_accuracy'], label='validation')\n",
    "ax2.set_title('accuracy')\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mkyubuJSOzg3"
   },
   "source": [
    "## Inference\n",
    "\n",
    "For a better measure of the quality of the model, let's see the model accuracy for the test messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "test_scores = model.evaluate(dataset_test, verbose=2)\n",
    "print(\"Test set %s: %.2f%%\" % (model.metrics_names[1], test_scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at classification accuracies separately for each newsgroup, and compute a confusion matrix to see which newsgroups get mixed the most:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(dataset_test)\n",
    "\n",
    "cm=confusion_matrix(labels_test,\n",
    "                    np.argmax(test_predictions[0], axis=1),\n",
    "                    labels=list(range(20)))\n",
    "\n",
    "print('Classification accuracy for each newsgroup:'); print()\n",
    "labels = [l[0] for l in sorted(labels_index.items(), key=lambda x: x[1])]\n",
    "for i,j in enumerate(cm.diagonal()/cm.sum(axis=1)): print(\"%s: %.4f\" % (labels[i].ljust(26), j))\n",
    "print()\n",
    "\n",
    "print('Confusion matrix (rows: true newsgroup; columns: predicted newsgroup):'); print()\n",
    "np.set_printoptions(linewidth=9999)\n",
    "print(cm); print()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(cm, cmap=\"gray\", interpolation=\"none\")\n",
    "plt.title('Confusion matrix (rows: true newsgroup; columns: predicted newsgroup)')\n",
    "plt.grid(None)\n",
    "tick_marks = np.arange(len(labels))\n",
    "plt.xticks(tick_marks, labels, rotation=90)\n",
    "plt.yticks(tick_marks, labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT Fine-Tuning Sentence Classification.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "python3.7",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
