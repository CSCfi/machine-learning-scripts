{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB movie review sentiment classification with BERTs (aclImdb version)\n",
    "\n",
    "In this notebook, we'll use pretrained and finetuned BERT models for sentiment classification using **Tensorflow** with the **Keras API**. \n",
    "\n",
    "**Note that using a GPU with this notebook is highly recommended.**\n",
    "\n",
    "When running this notebook in Colab, execute these shell commands first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%shell\n",
    "\n",
    "pip install keras_nlp\n",
    "wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "tar xf aclImdb_v1.tar.gz\n",
    "mv aclImdb/train/unsup /aclImdb/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import keras_nlp\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "print('Using Tensorflow version: {}, and Keras version: {}.'.format(tf.__version__, tf.keras.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if we have GPU available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "USE_FP16 = False\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if len(gpus) > 0:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    from tensorflow.python.client import device_lib\n",
    "    for d in device_lib.list_local_devices():\n",
    "        if d.device_type == 'GPU':\n",
    "            print('GPU', d.physical_device_desc)\n",
    "    if USE_FP16:\n",
    "        keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "else:\n",
    "    print('No GPU, using CPU instead. This notebook will probably be slow.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB data set\n",
    "\n",
    "Next we'll load the IMDB data set. We use the *aclImdb* version here as we need the original, non-tokenized  reviews.\n",
    "\n",
    "The dataset contains 50000 movies reviews from the Internet Movie Database, split into 25000 reviews for training and 25000 reviews for testing. We reserve 20% of the training reviews for validation.\n",
    "Half of the reviews are positive and half are negative.\n",
    "\n",
    "The dataset consists of movie reviews as text files in a directory hierarchy, and we use the `text_dataset_from_directory()` function to create a `tf.data.Dataset()` from the text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"/content\" # assuming Colab here\n",
    "BATCH_SIZE = 128\n",
    "validation_split=0.2\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train:')\n",
    "imdb_train = tf.keras.utils.text_dataset_from_directory(\n",
    "    DATADIR+\"/aclImdb/train\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=validation_split,\n",
    "    subset='training',\n",
    "    seed=seed\n",
    ")\n",
    "print('\\nValidation:')\n",
    "imdb_valid = tf.keras.utils.text_dataset_from_directory(\n",
    "    DATADIR+\"/aclImdb/train\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=validation_split,\n",
    "    subset='validation',\n",
    "    seed=seed\n",
    ")\n",
    "print('\\nTest:')\n",
    "imdb_test = tf.keras.utils.text_dataset_from_directory(\n",
    "    DATADIR+\"/aclImdb/test\",\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "print('\\nAn example review:')\n",
    "print(imdb_train.unbatch().take(1).get_single_element())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained BERT model\n",
    "\n",
    "In this section, we use a BERT model pretrained for sentiment classification without any further training.\n",
    "\n",
    "### Initialization\n",
    "\n",
    "Let's load the pretrained BERT model from KerasNLP: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertmodel = keras_nlp.models.BertClassifier.from_preset(\"bert_tiny_en_uncased_sst2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(bertmodel, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "We evaluate the quality of the model with classification accuracy for the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = bertmodel.evaluate(imdb_test, verbose=2)\n",
    "for i, m in enumerate(bertmodel.metrics_names):\n",
    "    print(\"%s: %.4f\" % (m, scores[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting sentiments for new reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myreview = 'This movie was the worst I have ever seen and the actors were horrible.'\n",
    "#myreview = 'This movie is great and I madly love the plot from beginning to end.'\n",
    "\n",
    "logits = bertmodel.predict([myreview], batch_size=1)\n",
    "probs = tf.nn.softmax(logits).numpy().squeeze()\n",
    "print('Predicted sentiment: {}TIVE ({:.4f}/{:.4f})'.format(\"POSI\" if probs[1]>probs[0] else \"NEGA\", probs[0], probs[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuned BERT model\n",
    "\n",
    "In this section, we finetune a pretrained backbone BERT model for sentiment classification.\n",
    "\n",
    "### Initialization\n",
    "\n",
    "Let's load the pretrained backbone BERT model from KerasNLP and prepare it for two output classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertmodel2 = keras_nlp.models.BertClassifier.from_preset(\n",
    "    \"bert_tiny_en_uncased\",\n",
    "    num_classes=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(bertmodel2, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning\n",
    "\n",
    "Let's train the model one epoch at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "bertmodel2.fit(imdb_train,\n",
    "               validation_data=imdb_valid,\n",
    "               epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "We again evaluate the quality of the model with the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores2 = bertmodel2.evaluate(imdb_test, verbose=2)\n",
    "for i, m in enumerate(bertmodel2.metrics_names):\n",
    "    print(\"%s: %.4f\" % (m, scores2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myreview = 'This movie was the worst I have ever seen and the actors were horrible.'\n",
    "#myreview = 'This movie is great and I madly love the plot from beginning to end.'\n",
    "\n",
    "logits = bertmodel2.predict([myreview], batch_size=1)\n",
    "probs = tf.nn.softmax(logits).numpy().squeeze()\n",
    "print('Predicted sentiment: {}TIVE ({:.4f}/{:.4f})'.format(\"POSI\" if probs[1]>probs[0] else \"NEGA\", probs[0], probs[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*Run this notebook in Google Colaboratory using [this link](https://colab.research.google.com/github/csc-training/intro-to-dl/blob/master/day1/optional/tf2-aclImdb-bert.ipynb).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
