{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB movie review sentiment classification with BERTs (aclImdb version)\n",
    "\n",
    "In this notebook, we'll use a pretrained BERT model for sentiment classification using **Tensorflow** with the **Keras API**. \n",
    "\n",
    "First, the needed imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import keras_nlp\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "print('Using Tensorflow version: {}, and Keras version: {}.'.format(tf.__version__, tf.keras.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if we have GPU available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_fp16 = False\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if len(gpus) > 0:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    from tensorflow.python.client import device_lib\n",
    "    for d in device_lib.list_local_devices():\n",
    "        if d.device_type == 'GPU':\n",
    "            print('GPU', d.physical_device_desc)\n",
    "    if use_fp16:\n",
    "        keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "else:\n",
    "    print('No GPU, using CPU instead.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB data set\n",
    "\n",
    "Next we'll load the IMDB data set. First time we may have to download the data, which can take a while.\n",
    "\n",
    "The dataset contains 50000 movies reviews from the Internet Movie Database, split into 25000 reviews for training and 25000 reviews for testing. Half of the reviews are positive (1) and half are negative (0).\n",
    "\n",
    "The dataset consists of movie reviews as text files in a directory hierarchy, and we use the `text_dataset_from_directory()` function to create a `tf.data.Dataset()` from the text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"/media/gpu-data/imdb\"\n",
    "BATCH_SIZE = 16\n",
    "validation_split=0.2\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train:')\n",
    "imdb_train = tf.keras.utils.text_dataset_from_directory(\n",
    "    DATADIR+\"/aclImdb/train\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=validation_split,\n",
    "    subset='training',\n",
    "    seed=seed\n",
    ")\n",
    "print('\\nValidation:')\n",
    "imdb_valid = tf.keras.utils.text_dataset_from_directory(\n",
    "    DATADIR+\"/aclImdb/train\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=validation_split,\n",
    "    subset='validation',\n",
    "    seed=seed\n",
    ")\n",
    "print('\\nTest:')\n",
    "imdb_test = tf.keras.utils.text_dataset_from_directory(\n",
    "    DATADIR+\"/aclImdb/test\",\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "print('\\nAn example review:')\n",
    "print(imdb_train.unbatch().take(1).get_single_element())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained BERT model\n",
    "\n",
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertmodel = keras_nlp.models.BertClassifier.from_preset(\"bert_tiny_en_uncased_sst2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(bertmodel, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = bertmodel.evaluate(imdb_test, verbose=2)\n",
    "for i, m in enumerate(bertmodel.metrics_names):\n",
    "    print(\"%s: %.4f\" % (m, scores[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myreview = 'This movie was the worst I have ever seen and the actors were horrible.'\n",
    "#myreview = 'This movie is great and I madly love the plot from beginning to end.'\n",
    "\n",
    "logits = bertmodel.predict([myreview], batch_size=1)\n",
    "probs = tf.nn.softmax(logits).numpy().squeeze()\n",
    "print('Predicted sentiment: {}TIVE ({:.4f}/{:.4f})'.format(\"POSI\" if probs[1]>probs[0] else \"NEGA\", probs[0], probs[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuned BERT model\n",
    "\n",
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertmodel2 = keras_nlp.models.BertClassifier.from_preset(\n",
    "    \"bert_tiny_en_uncased\",\n",
    "    num_classes=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(bertmodel2, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "bertmodel2.fit(imdb_train,\n",
    "               validation_data=imdb_valid,\n",
    "               epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores2 = bertmodel2.evaluate(imdb_test, verbose=2)\n",
    "for i, m in enumerate(bertmodel2.metrics_names):\n",
    "    print(\"%s: %.4f\" % (m, scores2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myreview = 'This movie was the worst I have ever seen and the actors were horrible.'\n",
    "#myreview = 'This movie is great and I madly love the plot from beginning to end.'\n",
    "\n",
    "logits = bertmodel2.predict([myreview], batch_size=1)\n",
    "probs = tf.nn.softmax(logits).numpy().squeeze()\n",
    "print('Predicted sentiment: {}TIVE ({:.4f}/{:.4f})'.format(\"POSI\" if probs[1]>probs[0] else \"NEGA\", probs[0], probs[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*Run this notebook in Google Colaboratory using [this link](https://colab.research.google.com/github/csc-training/intro-to-dl/blob/master/day1/04-tf2-imdb-rnn.ipynb).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
