{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST handwritten digits classification with support vector machines \n",
    "\n",
    "In this notebook, we'll use [support vector machines (SVMs)](http://scikit-learn.org/stable/modules/svm.html#svm-classification) and related algorithms to classify MNIST digits using scikit-learn.\n",
    "\n",
    "First, the needed imports. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pml_utils import get_mnist, show_failures\n",
    "\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from distutils.version import LooseVersion as LV\n",
    "assert(LV(sklearn.__version__) >= LV(\"0.20\")), \"Version >= 0.20 of sklearn is required.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we load the MNIST data. First time it downloads the data, which can take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = get_mnist('MNIST')\n",
    "\n",
    "print('MNIST data loaded: train:',len(X_train),'test:',len(X_test))\n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test', X_test.shape)\n",
    "print('y_test', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM \n",
    "\n",
    "### Learning\n",
    "\n",
    "Our first classifier is a linear SVM trained with a subset of training data.  Let's use the [`LinearSVC`](http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC) class, as it is a specialized in linear SVMs. `C` is the penalty parameter.  (The general `SVC` has a similar `kernel=’linear’` option that can also be used.  The third option is to use `SGDClassifier`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "C = 1.0\n",
    "clf_lsvm = svm.LinearSVC(C=C)\n",
    "print(clf_lsvm.fit(X_train[:10000,:], y_train[:10000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training of a Linear SVM is rather fast, so it seems more data could easily be used in the training.\n",
    "\n",
    "Note also that the default multiclass strategy of `LinearSVM` is one-vs-rest.\n",
    "\n",
    "### Inference\n",
    "\n",
    "As the decision boundaries are linear, prediction with linear SVMs is fast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pred_lsvm = clf_lsvm.predict(X_test)\n",
    "print('Predicted', len(pred_lsvm), 'digits with accuracy:', accuracy_score(y_test, pred_lsvm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel SVM\n",
    "\n",
    "In addition to linear classification, SVMs can be used for non-linear classification by implicitly mapping the input features into high-dimensional feature spaces.  This is sometimes called the *kernel trick*, as the implicit mapping is often computationally cheaper than explicitly operating in the high-dimensional space.\n",
    "\n",
    "### Learning\n",
    "\n",
    "Let's train a *3rd degree polynomial kernel SVM* with the *one-vs-rest* strategy for multiclass classification. A Gaussian kernel, that is `kernel='rbf'` is another common choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "clf_ksvm = svm.SVC(decision_function_shape='ovr', kernel='poly', degree=3)\n",
    "print(clf_ksvm.fit(X_train[:10000,:], y_train[:10000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "Despite the kernel trick, prediction of new samples is noticeably slower than with the linear SVM.  The classification accuracy, on the other hand, is improved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pred_ksvm = clf_ksvm.predict(X_test)\n",
    "print('Predicted', len(pred_ksvm), 'digits with accuracy:', accuracy_score(y_test, pred_ksvm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix\n",
    "\n",
    "We can compute the confusion matrix to see which digits get mixed the most:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "labels=[str(i) for i in range(10)]\n",
    "print('Confusion matrix (rows: true classes; columns: predicted classes):'); print()\n",
    "cm=confusion_matrix(y_test, pred_ksvm, labels=labels)\n",
    "print(cm); print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we plot it as an image, we can see it more visually.  The matrix looks quite good as most image are on the diagonal, meaning they were classified correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(cm, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy, precision and recall\n",
    "\n",
    "Classification accuracy for each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for i,j in enumerate(cm.diagonal()/cm.sum(axis=1)): print(\"%d: %.4f\" % (i,j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision and recall for each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_ksvm, labels=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "#### Failure analysis\n",
    "\n",
    "We can also do some failure analysis.  Let's check the 10 first wrongly predicted digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "show_failures(pred_ksvm, y_test, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study the scikit-learn documentation of the linear and kernel [SVMs](http://scikit-learn.org/stable/modules/svm.html#svm) and the available SVM classes ([`SVC`](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC), [`NuSVC`](http://scikit-learn.org/stable/modules/generated/sklearn.svm.NuSVC.html#sklearn.svm.NuSVC) and [`LinearSVC`](http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC). Experiment with different hyperparameter values.\n",
    "\n",
    "Report the highest classification accuracy you manage to obtain. Also mark down the parameters you used, so others can try to reproduce your results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
