{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic sign classification with CNNs\n",
    "\n",
    "In this notebook, we'll train a convolutional neural network (CNN, ConvNet) to classify images of traffic signs from [The German Traffic Sign Recognition Benchmark](http://benchmark.ini.rub.de/?section=gtsrb&subsection=news) using TensorFlow 2.0 / Keras. This notebook is largely based on the blog post [Building powerful image classification models using very little data](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html) by Fran√ßois Chollet.\n",
    "\n",
    "**Note that using a GPU with this notebook is highly recommended.**\n",
    "\n",
    "First, the needed imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os, datetime\n",
    "import random\n",
    "import pathlib\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import applications, optimizers\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from PIL import Image\n",
    "\n",
    "print('Using Tensorflow version:', tf.__version__,\n",
    "      'Keras version:', tf.keras.__version__,\n",
    "      'backend:', tf.keras.backend.backend())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The training dataset consists of 5535 images of traffic signs of varying size. There are 43 different types of traffic signs:\n",
    "\n",
    "![title](imgs/gtsrb-montage.png)\n",
    "\n",
    "The validation and test sets consist of 999 and 12630 images, respectively.\n",
    "\n",
    "### Downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"/media/data/gtsrb/train-5535/\"\n",
    "nimages = dict()\n",
    "(nimages['train'], nimages['validation'], nimages['test']) = (5535, 999, 12630)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image paths and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths(dataset):\n",
    "    data_root = pathlib.Path(datapath+dataset)\n",
    "    image_paths = list(data_root.glob('*/*'))\n",
    "    image_paths = [str(path) for path in image_paths]\n",
    "    image_count = len(image_paths)\n",
    "    assert image_count == nimages[dataset], \"Found {} images, expected {}\".format(image_count, nimages[dataset])\n",
    "    return image_paths\n",
    "\n",
    "image_paths = dict()\n",
    "image_paths['train'] = get_paths('train')\n",
    "image_paths['validation'] = get_paths('validation')\n",
    "image_paths['test'] = get_paths('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = sorted(item.name for item in pathlib.Path(datapath+'train').glob('*/') if item.is_dir())\n",
    "label_to_index = dict((name, index) for index,name in enumerate(label_names))\n",
    "\n",
    "def get_labels(dataset):\n",
    "    return [label_to_index[pathlib.Path(path).parent.name]\n",
    "            for path in image_paths[dataset]]\n",
    "    \n",
    "image_labels = dict()\n",
    "image_labels['train'] = get_labels('train')\n",
    "image_labels['validation'] = get_labels('validation')\n",
    "image_labels['test'] = get_labels('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading\n",
    "\n",
    "We now define a function to load the images. The images are in PPM format, so we use the PIL library. Also we need to resize the images to a fixed size (`INPUT_IMAGE_SIZE`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_IMAGE_SIZE = [80, 80]\n",
    "\n",
    "def _load_image(path, label):\n",
    "    image = Image.open(path.numpy())\n",
    "    return np.array(image), label\n",
    "\n",
    "def load_image(path, label):\n",
    "    image, label = tf.py_function(_load_image, (path, label), (tf.float32, tf.int32))\n",
    "    image.set_shape([None, None, None])\n",
    "    label.set_shape([])\n",
    "    return tf.image.resize(image, INPUT_IMAGE_SIZE), label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF Datasets\n",
    "\n",
    "Let's now define our [TF `Dataset`s](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset#class_dataset) for training, validation, and test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((image_paths['train'],\n",
    "                                                    image_labels['train']))\n",
    "train_dataset = train_dataset.map(load_image, num_parallel_calls=10)\n",
    "train_dataset = train_dataset.shuffle(2000).batch(BATCH_SIZE, drop_remainder=True)\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((image_paths['validation'],\n",
    "                                                         image_labels['validation']))\n",
    "validation_dataset = validation_dataset.map(load_image, num_parallel_calls=10)\n",
    "validation_dataset = validation_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((image_paths['test'],\n",
    "                                                   image_labels['test']))\n",
    "test_dataset = test_dataset.map(load_image, num_parallel_calls=10)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see a couple of our training images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for batch, labels in train_dataset.take(1):\n",
    "    for i in range(9):    \n",
    "        plt.subplot(3,3,i+1)\n",
    "        plt.imshow(tf.cast(batch[i,:,:,:], tf.int32))\n",
    "        plt.title(label_names[labels[i]])\n",
    "        plt.grid(False)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.suptitle('some training images', fontsize=16, y=0.93)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Train a small CNN from scratch\n",
    "\n",
    "Similarly as with MNIST digits, we can start from scratch and train a CNN for the classification task.\n",
    "\n",
    "However, due to the small number of training images, a large network will easily overfit.\n",
    "Therefore, to make the most of our limited number of training examples, we'll apply random augmentation transformations (small random crop and contrast adjustment) to them each time we are looping over them. This way, we \"augment\" our training dataset to contain more data.\n",
    "\n",
    "The augmentation transformations are implemented as preprocessing layers in Keras.\n",
    "There are various such layers readily available, see [https://keras.io/guides/preprocessing_layers/](https://keras.io/guides/preprocessing_layers/) for more information.\n",
    "\n",
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=INPUT_IMAGE_SIZE+[3])\n",
    "x = layers.Rescaling(scale=1./255)(inputs)\n",
    "\n",
    "x = layers.RandomCrop(75, 75)(x)\n",
    "x = layers.RandomContrast(0.1)(x)\n",
    "\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "outputs = layers.Dense(43, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs,\n",
    "                    name=\"gtsrb-small-cnn\")\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, 'tf2-gtsrb-small-cnn.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use TensorBoard to visualize our progress during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join(os.getcwd(), \"logs\",\n",
    "                      \"gtsrb-small-cnn-\"+datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "print('TensorBoard log directory:', logdir)\n",
    "os.makedirs(logdir)\n",
    "callbacks = [TensorBoard(log_dir=logdir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 20 \n",
    "\n",
    "history = model.fit(train_dataset, epochs=epochs,\n",
    "                    validation_data=validation_dataset,\n",
    "                    callbacks=callbacks, verbose=2)\n",
    "\n",
    "model.save(\"gtsrb-small-cnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,3))\n",
    "\n",
    "ax1.plot(history.epoch,history.history['loss'], label='training')\n",
    "ax1.plot(history.epoch,history.history['val_loss'], label='validation')\n",
    "ax1.set_title('loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.legend(loc='best')\n",
    "\n",
    "ax2.plot(history.epoch,history.history['accuracy'], label='training')\n",
    "ax2.plot(history.epoch,history.history['val_accuracy'], label='validation')\n",
    "ax2.set_title('accuracy')\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "scores = model.evaluate(test_dataset, verbose=2)\n",
    "print(\"Test set %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Reuse a pre-trained CNN\n",
    "\n",
    "Another option is to reuse a pretrained network.  Here we'll use the [VGG16](https://keras.io/applications/#vgg16) network architecture with weights learned using Imagenet. \n",
    "\n",
    "### Initialization\n",
    "\n",
    "We load the pretrained VGG16 network, remove the top layers, and freeze the pre-trained weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=INPUT_IMAGE_SIZE+[3])\n",
    "x = layers.Rescaling(scale=1./255)(inputs)\n",
    "\n",
    "x = layers.RandomCrop(75, 75)(x)\n",
    "x = layers.RandomContrast(0.1)(x)\n",
    "\n",
    "pt_model = applications.VGG16(weights='imagenet', include_top=False,      \n",
    "                              input_tensor=x)\n",
    "for layer in pt_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then stack our own, randomly initialized layers on top of the VGG16 network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Flatten()(pt_model.output)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "outputs = layers.Dense(43, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs,\n",
    "                    name=\"gtsrb-vgg16-reuse\")\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, 'tf2-dvc-vgg16-reuse.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning 1: New layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join(os.getcwd(), \"logs\",\n",
    "                      \"gtsrb-vgg16-\"+datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "print('TensorBoard log directory:', logdir)\n",
    "os.makedirs(logdir)\n",
    "callbacks_pretrained = [TensorBoard(log_dir=logdir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 20 \n",
    "\n",
    "history = model.fit(train_dataset, epochs=epochs,\n",
    "                    validation_data=validation_dataset,\n",
    "                    verbose=2, callbacks=callbacks_pretrained)\n",
    "\n",
    "model.save(\"gtsrb-vgg16-reuse.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,3))\n",
    "\n",
    "ax1.plot(history.epoch,history.history['loss'], label='training')\n",
    "ax1.plot(history.epoch,history.history['val_loss'], label='validation')\n",
    "ax1.set_title('loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.legend(loc='best')\n",
    "\n",
    "ax2.plot(history.epoch,history.history['accuracy'], label='training')\n",
    "ax2.plot(history.epoch,history.history['val_accuracy'], label='validation')\n",
    "ax2.set_title('accuracy')\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "scores = model.evaluate(test_dataset, verbose=2)\n",
    "print(\"Test set %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning 2: Fine-tuning\n",
    "\n",
    "Once the top layers have learned some reasonable weights, we can continue training by unfreezing the last convolution block of VGG16 (`block5`) so that it may adapt to our data. The learning rate should be smaller than usual. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_layer = False\n",
    "for layer in model.layers:\n",
    "    if layer.name == \"block5_conv1\":\n",
    "        train_layer = True\n",
    "    layer.trainable = train_layer\n",
    "    \n",
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name, \"trainable:\", layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "    optimizer=optimizers.RMSprop(learning_rate=1e-5),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join(os.getcwd(), \"logs\",\n",
    "                      \"gtsrb-vgg16-finetune-\"+datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "print('TensorBoard log directory:', logdir)\n",
    "os.makedirs(logdir)\n",
    "callbacks_pretrained = [TensorBoard(log_dir=logdir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 20 \n",
    "\n",
    "history = model.fit(train_dataset, epochs=epochs,\n",
    "                    validation_data=validation_dataset,\n",
    "                    verbose=2, callbacks=callbacks_pretrained)\n",
    "\n",
    "model.save(\"gtsrb-vgg16-finetune.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,3))\n",
    "\n",
    "ax1.plot(history.epoch,history.history['loss'], label='training')\n",
    "ax1.plot(history.epoch,history.history['val_loss'], label='validation')\n",
    "ax1.set_title('loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.legend(loc='best')\n",
    "\n",
    "ax2.plot(history.epoch,history.history['accuracy'], label='training')\n",
    "ax2.plot(history.epoch,history.history['val_accuracy'], label='validation')\n",
    "ax2.set_title('accuracy')\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "scores = model.evaluate(test_dataset, verbose=2)\n",
    "print(\"Test set %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.7",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
